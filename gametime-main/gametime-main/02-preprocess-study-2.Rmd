# Process AC:NH data

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE, 
  cache = FALSE
)
dir.create("data/noa/", FALSE, TRUE)
dir.create("data-raw/noa/", FALSE, TRUE)
```

Here, we process the AC:NH survey and telemetry files.

We used the following R packages:

```{r}
library(pacman)
p_load(
  readxl,
  knitr,
  here,
  lubridate,
  scales,
  janitor,
  tidyverse
)
```

## Raw data

This script expects the raw data files to be in `data-raw/noa/`. The raw telemetry and survey files are in a zip compressed file on OSF: <https://osf.io/cjd6z/>. Below, we provide code that downloads and unpacks these files.

The raw survey data was edited to exclude test sessions, any data from individuals who did not consent / below 18, and some unnecessary variables, before uploading to OSF. The code to do that is shown below (but cannot be executed without our formr credentials)

```{r eval = FALSE, error = TRUE}
# Dont download if already downloaded
if (!file.exists(here("data-raw/noa/formr-raw.rds"))) {
  # Connect to formr
  formr::formr_connect()
  # These are the survey names on formr
  surveys <- c("gaming_welcome", paste0("gaming_block", 2:5))
  # Download data into a list of data frames
  ac <- map(surveys, ~formr::formr_results(.) %>% as_tibble)
  saveRDS(ac, here("data-raw/noa/formr-raw.rds"))
} else {ac <- readRDS(here("data-raw/noa/formr-raw.rds"))}

# Take out all intermediate time variables
ac[[1]] <- select(ac[[1]], -c(modified:expired))
ac[2:4] <- map(ac[2:4], ~select(., -c(created:expired)))
ac[[5]] <- select(ac[[5]], -c(created, modified, expired))

# Transform to one data frame with one row per participant
ac <- ac %>% reduce(left_join)

# Limit data to survey window to exclude our test sessions
ac <- ac %>% 
  filter(created >= ymd("2020-10-27")) %>% 
  filter(created <= ymd("2020-10-27") + days(7))
range(ac$created)

# Keep only surveys whose code exists and consents check out
ac <- filter(
  ac, !is.na(code), of_age==1, consent_data==1, consent==1
)

# Take out unnecessary variables
ac <- ac %>% 
  select(
    -c(session, browser, last_outside_referrer, of_age:consent)
  )
write_rds(ac, here("data-raw/noa/formr.rds"))
```

The file produced by the above code chunk was uploaded to OSF in a zip compressed archive with the telemetry file.

Start by downloading that file and unpacking it to the target directory by running the code below:

```{r}
file_dest <- here("data-raw/noa/noa.zip")
# Download & extract file only if you haven't yet
if (!file.exists(file_dest)) {
  download.file("https://osf.io/fev95/download", file_dest)
}
if (!file.exists(here("data-raw/noa/formr.rds"))) {
  unzip(file_dest, exdir = here("data-raw/noa/"))
  
}
```

Next, we load the survey data file.

```{r}
ac <- readRDS(here("data-raw/noa/formr.rds"))
```

## Process raw files

### Clean survey data

Here, we clean the survey data.
Specifically, we

- Harmonize names so that they are the same as in the other data set (i.e., from PvZ)
- Create duration variable for game time
- Give some sensible variable names
- Assign proper variable types

```{r}
# Harmonize some names to PvZ names
ac <- ac %>% 
  rename(
    gender = sex,
    gender_other = sex_other,
    player_id = code
    )

# Duration of survey
ac <- ac %>% 
  mutate(
    survey_duration = ended-created
  )
# Create variables for straightliners by checking if variance within a block of questions is zero
ac$straightliner_spane <- apply(
  select(ac, starts_with("spane_") & !starts_with("spane_acnh")), 
  1, sd, na.rm = TRUE
)
ac$straightliner_spane <- ac$straightliner_spane==0
ac$straightliner_motivations <- apply(
  select(
    ac, 
    starts_with("autonomy_"), 
    starts_with("competence_"), 
    starts_with("related_"), 
    starts_with("enjoymen_"), 
    starts_with("extrinsic_")
  ), 
  1, sd, na.rm = TRUE
)
ac$straightliner_motivations <- ac$straightliner_motivations==0

# These are needed as factors
ac <- ac %>% 
  mutate(across(c(gender, played), as_factor))

# Reverse scored items
ac <- ac %>% 
  mutate(
    across(
      c(
        related_not_close,
        enjoyment_attention,
        enjoymen_boring
      ),
      ~ 8 - .x
    )
  )
```

Next, let's create mean indices for the scales like we did before.
SPANE has positive affect, negative affect, and an affect balance score (subtract negative from positive).
```{r create-scales}
# Need to rename SPANE item so it doesnt become confused with scale score name
ac <- rename(
  ac, 
  spane_positiveItem = spane_positive,
  spane_negativeItem = spane_negative
)

# General SPANE
ac <- ac %>% 
  mutate(
    spane_positive = rowMeans(
      select(
        .,
        spane_positiveItem,
        spane_good,
        spane_pleasant,
        spane_happy,
        spane_joyful,
        spane_contented
      ),
      na.rm = TRUE
    ),
    spane_negative = rowMeans(
      select(
        .,
        spane_negativeItem,
        spane_bad,
        spane_unpleasant,
        spane_sad,
        spane_afraid,
        spane_angry
      ),
      na.rm = TRUE
    ),
    spane_balance = spane_positive - spane_negative
  )

# Motivations
ac <- ac %>% 
  mutate(
    autonomy = rowMeans(
      select(., starts_with("autonomy")), na.rm = TRUE
    ),
    competence = rowMeans(
      select(., starts_with("competence")), na.rm = TRUE
    ),
    relatedness = rowMeans(
      select(., starts_with("related")), na.rm = TRUE
    ),
    enjoyment = rowMeans(
      select(., starts_with("enjoymen")), na.rm = TRUE
    ),
    extrinsic = rowMeans(
      select(., starts_with("extrinsic")), na.rm = TRUE
    )
  )

# SPANE because of playing AC:NH
ac <- ac %>% 
  mutate(
    spane_game_positive = rowMeans(
      select(
        .,
        spane_acnh_positive,
        spane_acnh_good,
        spane_acnh_pleasant,
        spane_acnh_happy,
        spane_acnh_joyful,
        spane_acnh_contented
      ),
      na.rm = TRUE
    ),
    spane_game_negative = rowMeans(
      select(
        .,
        spane_acnh_negative,
        spane_acnh_bad,
        spane_acnh_unpleasant,
        spane_acnh_sad,
        spane_acnh_afraid,
        spane_acnh_angry
      ),
      na.rm = TRUE
    ),
    spane_game_balance = spane_game_positive - spane_game_negative
  )

# Hours of estimated play
ac <- ac %>%
  mutate(active_play_minutes = active_play_minutes / 60) %>% 
  mutate(active_play = rowSums(select(., starts_with("active_play")), na.rm = T))
```

### Checking

First, we check how many rows per player there are.

```{r}
count(ac, player_id, sort = T)
```

There are two kinds of problems:

1. No ID was captured
2. An ID was used more than once

For both cases, connecting to telemetry would be impossible (and wrong connections could be made in latter case), so we drop these cases.

```{r}
ac <- add_count(ac, player_id) %>% 
  filter(n == 1) %>% 
  select(-n)
```

### Telemetry

This file is in the ZIP archive.

```{r}
gt <- read_tsv(here("data-raw/noa/telem_data (since Sep 2020).txt"))
```

Column definitions:

- `lc_recorded_at` = Session start date/time
- `nc_recorded_at` = Session end date/time
- `hashed_id` = Hashed account ID
- `product_model` =	Switch model game was played on
- `operation_mode` = Identifies handheld mode, TV mode
- `duration` = Duration of session (seconds)
- `storage_id` = Whether game is played off game card, SD card or internal system memory
- `application_id_hex` = Game's hashed ID

We drop some unnecessary variables

```{r}
gt <- select(
  gt,
  hashed_id, 
  contains("recorded"),
  duration
)
```

Then rename

```{r}
names(gt) <- c(
  "player_id", "session_start", "session_end", "Hours"
)
```

And turn duration into hours

```{r}
gt$Hours <- gt$Hours/60/60
```

Assume that timestamps are US Pacific as this was used to report data collection dates & times.

```{r}
gt <- gt %>% 
  mutate(
    across(contains("session"), ~mdy_hm(.x, tz = "US/Pacific"))
  )
glimpse(gt)
```

### Clean

We don't need to limit to IDs who took the survey as NOA has already done that--these data only contain folks who filled in the survey.

We do need to limit the data to two weeks preceding the survey, and count session durations within that window. We therefore need to use the session start/end times to find out when the sessions happened.

Some processing is required to do that as the times can have noise due to e.g. players' system times being incorrectly set. Thus, many start times are the same (or even later) than the end time:

```{r}
gt %>% 
  mutate(
    later_or_same_start = session_start >= session_end
  ) %>% 
  tabyl(later_or_same_start) %>% 
  adorn_pct_formatting()
```

However, session durations are not based on the device time (session times):

```{r}
gt %>% 
  mutate(
    duration = as.numeric(session_end - session_start)/60/60
  ) %>% 
  mutate(match = duration/60/60==Hours) %>% 
  tabyl(match) %>% 
  adorn_pct_formatting()
```

And end and start times should be within a window. 

```{r}
tmp <- gt %>% 
  filter(
    session_start < ymd("2020-09-01") |
      session_end < ymd("2020-09-01") |
      session_start > ymd("2020-11-03") |
      session_end > ymd("2020-11-03") 
  ) %>% 
  arrange(session_start) %>% 
  mutate(player_id = fct_inorder(player_id))
# Proportion of these bad dates
percent(nrow(tmp) / nrow(gt), .1)
```

We filter out sessions that aren't in the two weeks preceding each player's survey. Note not all survey respondents have telemetry so the resulting table will be longer

```{r}
# Get survey times from survey table
gt <- select(ac, player_id, created) %>% 
  left_join(gt) 

# Limit telemetry sessions to appropriate time window
gt <- gt %>%   
  filter(session_start >= (created - days(14))) %>% 
  filter(session_start < created) %>% 
  filter(session_end < created)
```

We then summarize to total hours per person.

```{r}
gt <- gt %>% 
  group_by(player_id) %>% 
  summarise(
    Hours = sum(Hours), 
    n_sessions = n()
  )
```

### Join survey and telemetry

```{r}
ac <- left_join(ac, gt)
```

### Checking

People reported if they played AC:NH in the past 14 days. Lets summarise the players, number of players with telemetry, and mean hours, for these two groups

```{r}
ac %>% 
  group_by(played) %>% 
  summarise(
    Players = n(),
    Missing_Hours = sum(is.na(Hours)),
    Mean_Hours = mean(Hours, na.rm = TRUE)
  )
```

## Exclusions

First save a file with no exclusions.

```{r}
write_rds(ac, here("data/noa/ac.rds"))
```

### Straightliners

We take out all individuals who straightlined (gave the same response to every item) through SPANE and motivations scales. (If only SPANE items existed, then we didn't exclude.)

```{r}
ac <- ac %>% 
  mutate(
    straightliner = 
      straightliner_spane & straightliner_motivations
  ) 
ac %>%   
  select(contains("straight")) %>% 
  group_by_all() %>% 
  count
ac %>%   
  tabyl(straightliner) %>% 
  adorn_pct_formatting()
# filter() would also exclude NAs
ac <- filter(ac, !straightliner | is.na(straightliner))
```

### Outliers

Potential outliers. We replace all values that are more than 6SD away from the variable's mean with NAs. As a consequence, individuals are excluded on an analysis-by-analysis case (so if has bad data relevant to that analysis or figure).

This is only done for a subset of variables (relavant to analyses; see below)

```{r}
ac <- ac %>% 
  # These variables will be affected
  pivot_longer(
    c(
      spane_positiveItem:Hours, 
      -played_with_others, -ended, -survey_duration,
      -contains("straightliner")
    )
  ) %>% 
  group_by(name) %>% 
  mutate(z_value = as.numeric(scale(value))) 
```

These are the numbers of people taken out of each variable (only variables that were affected are shown):

```{r}
# This is what are taken out
ac %>% 
  summarise(
    Extremes = sum(abs(z_value>=6), na.rm = TRUE),
    Extremes_p = percent(Extremes/n(), accuracy = .01)
  ) %>% 
  filter(Extremes > 0)
```

Code to do it:

```{r}
ac <- ac %>%
  mutate(value = ifelse(abs(z_value >= 6), NA, value)) %>% 
  select(-z_value) %>% 
  pivot_wider(names_from = "name", values_from = "value") %>% 
  ungroup()
```

## Save files

```{r}
write_rds(ac, here("data/noa/ac-excluded.rds"))
```

## Session info
```{r}
sessionInfo()
```

