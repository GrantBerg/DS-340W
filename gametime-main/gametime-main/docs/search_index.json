[["index.html", "Video game play is positively correlated with well-being 1 Preface 1.1 Raw data 1.2 Analyses and reproducibility", " Video game play is positively correlated with well-being Niklas Johannes, Matti Vuorre, Andrew Przybylski 2020-12-16 1 Preface Data analyses related to “Video game play is positively correlated with well-being” (Johannes, Vuorre, Przybylski, in prep) Preprint: https://psyarxiv.com/qrjza/ 1.1 Raw data The raw data are in zip compressed files at https://osf.io/fev95/. Those files were minimally processed to e.g. remove test survey sessions, as described in the following sections. 1.2 Analyses and reproducibility The data analyses are organized into separate R Markdown files for processing, describing, and modelling. The source code is on GitHub: https://github.com/digital-wellbeing/gametime. Those source files are organized as a R bookdown project, whose results are at https://digital-wellbeing.github.io/gametime. To reproduce our analyses, download the source files and build the book (e.g. in RStudio click the “Build Book” button). The results are rendered to docs/index.html and can be viewed in a web browser. "],["process-pvz-data.html", "2 Process PVZ data 2.1 Raw data 2.2 Process raw files 2.3 Merge survey and telemetry 2.4 Exclusions 2.5 Save files 2.6 Session info", " 2 Process PVZ data Here, we process the Plants vs. Zombies: Battle for Neighborville (PVZ) survey and telemetry data files (i.e., gaming data that was captured by EA’s servers). We used the following R packages. Pacman is a package manager that install packages if you don’t have them installed. We always show the package versions at the bottom of each section. library(pacman) p_load( readxl, knitr, here, lubridate, scales, janitor, anytime, tidyverse ) 2.1 Raw data The raw data files, including the raw survey data, are in a zip compressed file on OSF: https://osf.io/cjd6z/. (A user ID column was manually removed from the survey data before uploading.) Start by downloading that file and unpacking it to the target directory: file_dest &lt;- here(&quot;data-raw/ea/ea.zip&quot;) # Download &amp; extract file only if you haven&#39;t yet if (!file.exists(file_dest)) { download.file(&quot;https://osf.io/4gp3r/download&quot;, file_dest) } if (!file.exists(here(&quot;data-raw/ea/Oxford PvZ - Pilot Wave + Wave 1 Download.xlsx&quot;))) { unzip(file_dest, exdir = here(&quot;data-raw/ea/&quot;)) } EA sent out the survey in two waves: one in August of 2020, the second in September 2020. For each wave, there are 9 telemetry files, each one recording a different aspect of play events in Plants vs. Zombies: Battle for Neighborville and one file for the survey results. These telemetry files contain info on PVZ play events from a long period of time, including for players who did not participate in the survey. We limit our analyses to the individuals who participated in the survey, and to the 2 weeks preceding the survey. However, the raw data files might be of interest for additional analyses. 2.2 Process raw files Because there were two of each telemetry file (waves), we create a function to read both waves’ data into a single table: read_both_waves &lt;- function(stub = &quot;OII_PVZ_Authentications&quot;, ...) { # Filenames of wave 1 and 2 authentications files list.files( here(&quot;data-raw/ea&quot;), pattern = stub, full.names = TRUE ) %&gt;% # Put wave 1 first rev() %&gt;% # Read into a list of data frames map(read_csv, ...) %&gt;% # Bind into one data frame with wave ID bind_rows(.id = &quot;wave&quot;) %&gt;% # Take only participants who filled out survey filter(player_id %in% survey$player_id) } 2.2.1 Survey Because we only keep telemetry data of players who answered the survey, we’ll load the survey first. survey &lt;- read_excel( here(&quot;data-raw/ea/Oxford PvZ - Pilot Wave + Wave 1 Download.xlsx&quot;) ) survey &lt;- survey %&gt;% mutate( # Ensure date data type date = mdy_hm(date), # Need another name to use in filtering telemetry start_date = date ) %&gt;% # Other files use player_id rename(player_id = UID) 2.2.1.1 Clean and transform Next, we give some sensible variable names and assign proper variable types for the survey. # Rename variables survey &lt;- survey %&gt;% select( # meta-info player_id, start_date, date, survey_duration = qtime, of_age = Q2, consent = Q3, # demographics played = Q1, country = hCountry, survey_language = PRELANG, age = D1, gender = D2, gender_other = D2r3oe, experience = D3, # well-being spane_ = starts_with(&quot;A1&quot;), # general well-being in the two weeks straightliner_spane = hA1Straight, # motivations played_with_others = NSat1, # filter question that determines whether relatedness items were shown autonomy_ = NSat2r1:NSat2r3, competence_ = NSat2r4:NSat2r6, relatedness_ = NSat2r7:NSat2r9, enjoyment_ = NSat2r10:NSat2r13, extrinsic_ = NSat2r14:NSat2r17, straightliner_motivations = hNSat2Straight, # self-reported play active_play_hours = GT1c1, active_play_minutes = GT1c2, within_estimate = GT2, between_estimate = GT3, spane_game_ = starts_with(&quot;GT4&quot;) ) # Assign proper variable types and factor levels survey &lt;- survey %&gt;% mutate( across( c( player_id, of_age:survey_language, gender, played_with_others ), as.factor ), across( c(of_age:played, played_with_others), ~ fct_recode( .x, &quot;Yes&quot; = &quot;1&quot;, &quot;No&quot; = &quot;2&quot; ) ), gender = fct_recode( gender, &quot;Male&quot; = &quot;1&quot;, &quot;Female&quot; = &quot;2&quot;, &quot;Other&quot; = &quot;3&quot;, &quot;Prefer not to say&quot; = &quot;4&quot; ), country = fct_recode( country, &quot;US&quot; = &quot;1&quot;, &quot;UK&quot; = &quot;2&quot;, &quot;Canada&quot; = &quot;5&quot; ), survey_language = fct_recode( survey_language, &quot;English&quot; = &quot;1&quot;, &quot;French&quot; = &quot;2&quot; ) ) # Reverse scored items survey &lt;- survey %&gt;% mutate( across( c( starts_with(&quot;spane&quot;), # 1 was never between_estimate, # those estimates also had 1: much more than typically within_estimate, relatedness_3, enjoyment_2, enjoyment_3 ), ~ 8 - .x ) ) # Indicators for straightliners survey &lt;- survey %&gt;% mutate(across(contains(&quot;straightliner&quot;), ~.x==1)) Then we create mean indices for the scales. SPANE has positive affect, negative affect, and an affect balance score (subtract negative from positive). # General SPANE survey &lt;- survey %&gt;% mutate( spane_positive = rowMeans( select( ., spane_1, spane_3, spane_5, spane_7, spane_10, spane_12 ), na.rm = TRUE ), spane_negative = rowMeans( select( ., spane_2, spane_4, spane_6, spane_8, spane_9, spane_11 ), na.rm = TRUE ), spane_balance = spane_positive - spane_negative ) # Motivations survey &lt;- survey %&gt;% mutate( autonomy = rowMeans( select(., starts_with(&quot;autonomy&quot;)), na.rm = TRUE ), competence = rowMeans( select(., starts_with(&quot;competence&quot;)), na.rm = TRUE ), relatedness = rowMeans( select(., starts_with(&quot;relatedness&quot;)), na.rm = TRUE ), enjoyment = rowMeans( select(., starts_with(&quot;enjoyment&quot;)), na.rm = TRUE ), extrinsic = rowMeans( select(., starts_with(&quot;extrinsic&quot;)), na.rm = TRUE ) ) # SPANE because of playing game survey &lt;- survey %&gt;% mutate( spane_game_positive = rowMeans( select( ., spane_game_1, spane_game_3, spane_game_5, spane_game_7, spane_game_10, spane_game_12 ), na.rm = TRUE ), spane_game_negative = rowMeans( select( ., spane_game_2, spane_game_4, spane_game_6, spane_game_8, spane_game_9, spane_game_11 ), na.rm = TRUE ), spane_game_balance = spane_game_positive - spane_game_negative ) # Hours of estimated play survey &lt;- survey %&gt;% mutate(active_play_minutes = active_play_minutes / 60) %&gt;% mutate(active_play = rowSums(select(., starts_with(&quot;active_play&quot;)), na.rm = T)) 2.2.2 Game time Then we get to the telemetry files. The game time data are the most complicated. We work on it first because the times are needed for some of the other telemetry files. Note: The raw excel files on the OSF (or downloaded as zip files above) have a detailed data map as the second tab of the file. These serve as a codebook. The data show us when a player started a session and how long that session lasted, plus whether they played the game in multiplayer or single player. The variables: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. game_start_time = Session start date time. game_end_time = Session end date time. game_mode = The game mode, primarily multiplayer or single player. game_type = Notes if the game is offline/online and if it is splitscreen game_level = The level’s name where the session took place. game_session = Unique identifier for a game session. game_time &lt;- read_both_waves(&quot;OII_PVZ_Game_Time&quot;) glimpse(game_time) ## Rows: 32,596 ## Columns: 11 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;… ## $ player_id &lt;chr&gt; &quot;FEDA2447DB60C134D1094C6B3C790CC66AA542CB6D0020870CCE… ## $ platform &lt;chr&gt; &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;XBox… ## $ game_start_time &lt;dttm&gt; 2020-07-29 15:48:37, 2020-07-29 16:25:07, 2020-07-29… ## $ game_end_time &lt;dttm&gt; 2020-07-29 16:03:37, 2020-07-29 16:29:05, 2020-07-29… ## $ game_mode &lt;chr&gt; &quot;multiplayer&quot;, &quot;multiplayer&quot;, &quot;multiplayer&quot;, &quot;singlep… ## $ game_type &lt;chr&gt; &quot;Online&quot;, &quot;Online&quot;, &quot;Offline&quot;, &quot;Offline&quot;, &quot;Online&quot;, &quot;… ## $ game_level &lt;chr&gt; &quot;pipeline&quot;, &quot;loggy acres&quot;, NA, NA, &quot;peachy district&quot;,… ## $ game_level_key &lt;chr&gt; &quot;dsub_region_cheesemines&quot;, &quot;dsub_rush_dreadwood&quot;, &quot;ds… ## $ game_session &lt;chr&gt; &quot;b72a6bd5578a55445a27885aa767261926206d1ee98492101283… ## $ server_session &lt;chr&gt; &quot;ea0ed44b4eef8704a68af4fd681000f22545a717b9ebbaf1d0f5… A game session starts when a player starts playing. That means game_session records when a match starts, which includes going to the Hub World (i.e., a world inside the game where players can decide what to do next). Game sessions can be shared between players when they’re playing multiplayer, but should be unique to a player_id when in single player. However, it’s not easy to say when a session ends for technical reasons. Ideally, we’d have one game session per row. Because it’s hard to determine when a session ends, there are instances where a given player has multiple rows with the same game_session. counts &lt;- game_time %&gt;% count(player_id, game_session, sort = T) For example, the player below has 107 rows with identical player_id and game_session. Some of those rows have identical start and end times for the session, but the majority are in “chunks” with the same start times, but slightly different end times. This pattern shows the problems with determining the end of a session. See the figure below to see how the rows overlap in their game durations. # example of one player_idXgame_session with multiple entries tmp &lt;- counts %&gt;% slice(1) %&gt;% left_join(game_time) %&gt;% arrange(game_start_time, game_end_time) tmp %&gt;% rowid_to_column() %&gt;% ggplot(aes(game_start_time, rowid, col = game_session)) + geom_segment(aes(xend = game_end_time, yend = rowid)) + facet_wrap(&quot;player_id&quot;, labeller = label_both) + theme(legend.position = &quot;bottom&quot;) For those instances where a player has multiple (overlapping) game sessions, we’ll simply use the earliest start time and latest end time of that “super-session” to collapse all overlapping rows into one. For that, we look for each combination of player_id and game_session and replace game_start_time with the earliest time within that super-session; likewise, we replace game_end_time with the latest time within that super-session. If a player only has one row, they’ll maintain that one row this way. If a player has multiple rows, they’re collapsed into one row that encompasses the game durations of all rows. See the figure below which now only has one duration for that player, which goes from the minimum to the maximum time of the previous figure. # Key point: Replace start and end times with first and last start/end time # then take unique rows. This results in 1 row per session. tmp &lt;- tmp %&gt;% group_by(player_id, game_session) %&gt;% mutate( game_start_time = min(game_start_time), game_end_time = max(game_end_time) ) %&gt;% slice(1) # distinct() didn&#39;t work when there were different levels within the same session last_plot() %+% mutate(tmp, rowid = 1:n()) Next, we apply this procedure to all players. However, some start times are missing, which won’t allow us to compute duration for that session. Whenever a game_start_time is missing, we’ll set it to the end time of that session. That creates game sessions with a duration of 0, which we’ll set to NA again later. (Note: game_end_time doesn’t have missing values, which is why we can use coalesce) game_time &lt;- game_time %&gt;% mutate( game_start_time = coalesce( game_start_time, game_end_time ) ) # now collapse the rows game_time &lt;- game_time %&gt;% group_by(player_id, game_session) %&gt;% mutate( game_start_time = min(game_start_time), game_end_time = max(game_end_time), ) %&gt;% # Take the first of each (identical) person-session combo slice(1) %&gt;% ungroup() Then we save the file. write_rds(game_time, here(&quot;data/ea/game_time.rds&quot;)) 2.2.3 Authentications The authentifications data set logs events when a player (player_id) logs into the game. The variables are: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. date = Date of the login. country = Country the login came from. authentications &lt;- read_both_waves(&quot;OII_PVZ_Authentications&quot;) glimpse(authentications) ## Rows: 3,203 ## Columns: 5 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;,… ## $ player_id &lt;chr&gt; &quot;827DA8326180689AE248395F63DE5ECA6AA542CB6D0020870CCE3A1312… ## $ platform &lt;chr&gt; &quot;XBox One&quot;, &quot;Playstation 4&quot;, &quot;Playstation 4&quot;, &quot;Playstation … ## $ date &lt;date&gt; 2020-08-02, 2020-08-07, 2020-07-29, 2020-07-28, 2020-07-30… ## $ country &lt;chr&gt; &quot;United Kingdom&quot;, &quot;United States&quot;, &quot;United States&quot;, &quot;United… First, we only keep authentications of players who also participated in the survey. Then we count how many times players logged in to PvZ. In the survey, players reflected on their well-being and gaming in the past two weeks, so we’ll only count those game events that occurred within 14 days prior to the time the participant took the survey. The date variable in authentications doesn’t have time, so we’ll make it easy and also reduce start_time in the survey to a date (without time of day). authentications &lt;- authentications %&gt;% # add the start date by player ID left_join(select(survey, player_id, start_date)) %&gt;% # only keep authentication events that occured within 14 days before the survey was taken filter(date &gt;= (as_date(start_date) - days(14)) ) %&gt;% count(player_id, name = &quot;authentications&quot;) 2.2.4 Characters The characters data provides performance stats for a player while they play as a specific character in the game. The variables are: player_id platform = One of the major platforms, eg. PC, Playstation, Xbox. game_session = Unique identifier for a game session. game_mode = The game mode, primarily multiplayer or single player. game_type = Notes if the game is offline/online and if it is splitscreen game_level = The level’s name where the session took place. character_class = The character key noting the character used. total_kill_count = Total kills earned by the player. total_death_count = Total deaths suffered by the player. score = Total score earned by the player. damage_dealt = Total damage dealt by the player. critical_hit_count = Number of critical hits earned by the player. shots_fired = Number of shots fired by the player. shots_hit = Number of shots by the player which successfully hit. characters &lt;- read_both_waves(&quot;OII_PVZ_Character&quot;) glimpse(characters) ## Rows: 36,621 ## Columns: 17 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, … ## $ player_id &lt;chr&gt; &quot;9C7114A674CDE6EF2D454798063FA11B6AA542CB6D0020870… ## $ platform &lt;chr&gt; &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;XBox One&quot;, &quot;X… ## $ game_session &lt;chr&gt; &quot;ffa2e2a92f96449d1af765c0d11e1931ff2cfffd9c8c64ed6… ## $ server_session &lt;chr&gt; &quot;d7725b7927d7d3c1222a03d4c53c6ceca7afc55106256905d… ## $ game_mode &lt;chr&gt; &quot;multiplayer&quot;, &quot;party&quot;, &quot;multiplayer&quot;, &quot;multiplaye… ## $ game_type &lt;chr&gt; &quot;Offline&quot;, &quot;Offline&quot;, &quot;Online&quot;, &quot;Online&quot;, &quot;Offline… ## $ game_level &lt;chr&gt; NA, NA, &quot;dugout&quot;, &quot;suburbs&quot;, &quot;temple&quot;, &quot;temple&quot;, &quot;… ## $ game_level_key &lt;chr&gt; &quot;dsub_social_terrain_summer&quot;, &quot;dsub_social_terrain… ## $ character_class &lt;chr&gt; &quot;[Unknown]&quot;, &quot;mpzombie_wizard&quot;, &quot;[Unknown]&quot;, &quot;mpzo… ## $ total_kill_count &lt;dbl&gt; NA, 0, NA, 9, 1, 0, 0, 0, NA, NA, NA, NA, NA, NA, … ## $ total_death_count &lt;dbl&gt; NA, 0, NA, 7, 0, 1, 2, 1, NA, NA, NA, NA, NA, NA, … ## $ score &lt;dbl&gt; NA, 0, NA, 1675, 200, 0, 0, 0, NA, NA, NA, NA, NA,… ## $ damage_dealt &lt;dbl&gt; NA, 0, NA, 978, 153, 213, 206, 233, NA, NA, NA, NA… ## $ critical_hit_count &lt;dbl&gt; NA, 0, NA, 73, 7, 1, 4, 10, NA, NA, NA, NA, NA, NA… ## $ shots_fired &lt;dbl&gt; NA, 0, NA, 350, 91, 20, 95, 30, NA, NA, NA, NA, NA… ## $ shots_hit &lt;dbl&gt; NA, 0, NA, 109, 22, 6, 20, 5, NA, NA, NA, NA, NA, … We do the same for the performance stats in the characters data set. The data set doesn’t have a start time for the game sessions, so we’ll add those start times by matching the player_id and game_session with those of the game_time data set, which has start times for the game sessions, thereby adding the game_start_time for a game session. Then we include only those game sessions that happened within 14 days of a participant taking the survey. After that, we sum up all player stats for that period. characters &lt;- characters %&gt;% left_join( game_time %&gt;% select(player_id, game_session, game_start_time), by = c(&quot;player_id&quot;, &quot;game_session&quot;) ) %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(game_start_time &gt;= (start_date - days(14))) %&gt;% group_by(player_id) %&gt;% summarise(across(total_kill_count:shots_hit, sum, na.rm = TRUE)) %&gt;% ungroup() 2.2.5 Friends The friends data show when two players became friends and at what time (in PvZ, not on the platform?). The variables: player_id = Unique identifier for a player. friend_player_id = Unique identifier for a player, who is marked as a friend of the player_id. date_time = The date time when the friend invite was accepted. friends &lt;- read_both_waves(&quot;OII_PVZ_Friends&quot;) write_rds(friends, here(&quot;data/ea/friends.rds&quot;)) glimpse(friends) ## Rows: 10,993 ## Columns: 4 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1… ## $ player_id &lt;chr&gt; &quot;2F4E5F9EBDE746571B4FEF0B1007FCBA6AA542CB6D0020870CC… ## $ friend_player_id &lt;chr&gt; &quot;bf8b08933cec0be8356bb274416f4d388dcf1f9f8d1071dc3ec… ## $ event_date_time &lt;dttm&gt; 2020-08-04 19:28:31, 2020-08-05 23:30:55, 2020-08-0… Then we count the number of friend connections made. player_id is the player; friend_player_id is the player who was sent a friend request from player_id. That means some players will be in the player_id column when they send a friend request, but also in the friend_player_id column when they receive a friend request. Therefore, we sum over sent and received friend connections in the 14 days prior to the survey. # filter out those that didn&#39;t happen within the past two weeks friends &lt;- friends %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(event_date_time &gt;= (start_date - days(14))) # get friend requests sent a &lt;- friends %&gt;% group_by(player_id) %&gt;% summarise(requests_sent = length(unique(friend_player_id))) # get friend requests received b &lt;- friends %&gt;% group_by(friend_player_id) %&gt;% summarise(requests_received = length(unique(player_id))) # add those new variables to the data friends &lt;- left_join(a, b, by = c(&quot;player_id&quot; = &quot;friend_player_id&quot;)) # not a lot of people received friend requests (meaning they&#39;re NA), so before adding sent and received up, we set NAs to zero friends &lt;- friends %&gt;% mutate( across( c(starts_with(&quot;requests&quot;)), ~ if_else(is.na(.x), 0L, .x) ), friends = requests_sent + requests_received ) %&gt;% select(-starts_with(&quot;requests&quot;)) rm(a, b) 2.2.6 Gestures The gesture data shows when a player used a gesture (gesture/emote/command) that can be seen by other players. The variables: player_id = Unique identifier for a player. gesture_key = Key name of the geature used. gesture_type = Whether the gesture was a gesture, command or emote. game_session = Unique identifier for a game session. date_time = The date time when the gesture was used. gestures &lt;- read_both_waves(&quot;OII_PVZ_Gesture&quot;) write_rds(gestures, here(&quot;data/ea/gestures.rds&quot;)) glimpse(gestures) ## Rows: 30,962 ## Columns: 6 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;… ## $ player_id &lt;chr&gt; &quot;E8EEB3797D51527FF55D5793C8A09CE56AA542CB6D0020870CCE3A1… ## $ gesture_key &lt;chr&gt; &quot;id_statement_hello&quot;, &quot;id_unlockitem_summernights_thatwa… ## $ gesture_type &lt;chr&gt; &quot;socialboarditemtype_command&quot;, &quot;socialboarditemtype_comm… ## $ game_session &lt;chr&gt; &quot;4f3d3fca76e2507bf480324b9c576955413b961ca2178e3670c6082… ## $ date_time &lt;dttm&gt; 2020-07-28 15:25:13, 2020-07-28 15:21:59, 2020-07-28 15… We first match only those sessions that were within the time frame, then count how many gestures a player used. gestures &lt;- gestures %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(date_time &gt;= (start_date - days(14))) %&gt;% count(player_id, name = &quot;gestures&quot;) 2.2.7 Leveling This data set shows when a player went up a level with a character. The variables: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. level = The level earned for the character. date_time = The date time when the level was earned. character_class = The character key noting the character used. leveling &lt;- read_both_waves(&quot;OII_PVZ_Leveling&quot;) write_rds(leveling, here(&quot;data/ea/leveling.rds&quot;)) glimpse(leveling) ## Rows: 12,197 ## Columns: 6 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;… ## $ player_id &lt;chr&gt; &quot;AB42AE2D06428AB6A90E37C2A40375016AA542CB6D0020870CCE… ## $ platform &lt;chr&gt; &quot;Playstation 4&quot;, &quot;Playstation 4&quot;, &quot;Windows PC&quot;, &quot;Play… ## $ level &lt;dbl&gt; 14, 13, 59, 6, 22, 19, 40, 23, 22, 23, 32, 43, 73, 44… ## $ date_time &lt;dttm&gt; 2020-08-03 08:44:27, 2020-08-03 08:42:57, 2020-08-03… ## $ character_class &lt;chr&gt; &quot;mpplant_rose&quot;, &quot;mpzombie_allstar&quot;, &quot;mpplant_peashoot… We only include those sessions that happened within the time frame, then we count how many times a player went up a level. leveling &lt;- leveling %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(date_time &gt;= (start_date - days(14))) %&gt;% count(player_id, name = &quot;levelings&quot;) 2.2.8 Prestige This data set show when a a player went up a prestige level with a character. Prestige levels are different from character levels. The variables: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. prestige_level = The prestige level for the character. date_time = The date time the prestige level was earned. character_class = The character key noting the character used. prestige &lt;- read_both_waves(&quot;OII_PVZ_Presti&quot;) glimpse(prestige) ## Rows: 309 ## Columns: 6 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;… ## $ player_id &lt;chr&gt; &quot;E8EEB3797D51527FF55D5793C8A09CE56AA542CB6D0020870CCE… ## $ platform &lt;chr&gt; &quot;XBox One&quot;, &quot;Playstation 4&quot;, &quot;Playstation 4&quot;, &quot;XBox O… ## $ prestige_level &lt;chr&gt; &quot;prst04&quot;, &quot;prst03&quot;, &quot;prst07&quot;, &quot;prst07&quot;, &quot;prst02&quot;, &quot;pr… ## $ date_time &lt;dttm&gt; 2020-07-28 15:47:51, 2020-08-01 23:05:52, 2020-07-30… ## $ character_class &lt;chr&gt; &quot;pac&quot;, &quot;acorn&quot;, &quot;ps&quot;, &quot;ci&quot;, &quot;sc&quot;, &quot;ch&quot;, &quot;ps&quot;, &quot;imp&quot;, … write_rds(prestige, here(&quot;data/ea/prestige.rds&quot;)) prestige &lt;- prestige %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(date_time &gt;= (start_date - days(14))) %&gt;% count(player_id, name = &quot;prestige&quot;) 2.2.9 Registrations Registrations only happen once per player and show when a player registered with PvZ for the first time. Won’t be needed later, but code is here for completeness. The variables: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. date = Date of the registration. country = Country the login came from. registrations &lt;- read_both_waves(&quot;OII_PVZ_Registration&quot;) 2.2.10 Experience Points This data set shows how many XP a player earned at what time and in what session. The variables: player_id = Unique identifier for a player. platform = One of the major platforms, eg. PC, Playstation, Xbox. date_time = The date time when the xp was earned. character_class = The character key noting the character used. game_session = Unique identifier for a game session. xp_earned = The xp amount earned. # Gotta process dates because they are different across the two files xp &lt;- read_both_waves( &quot;OII_PVZ_XPEarned&quot;, col_types = cols(date_time = &quot;c&quot;) ) # All other timestamps, above, are automatically parsed to UTC so we do that here as well xp &lt;- xp %&gt;% mutate(date_time = anytime(date_time, &quot;UTC&quot;)) glimpse(xp) ## Rows: 50,688 ## Columns: 8 ## $ wave &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;… ## $ player_id &lt;chr&gt; &quot;C27BB332C56E4C8222687847E037D1366AA542CB6D0020870CCE… ## $ platform &lt;chr&gt; &quot;Windows PC&quot;, &quot;Windows PC&quot;, &quot;Playstation 4&quot;, &quot;Windows… ## $ date_time &lt;dttm&gt; 2020-07-28 21:06:54, 2020-07-28 21:55:23, 2020-07-28… ## $ character_class &lt;chr&gt; &quot;mpplant_acorn&quot;, &quot;mpplant_assaultcorn&quot;, &quot;mpzombie_ast… ## $ game_session &lt;chr&gt; &quot;188f421f446d5b17137fd6fe913cd78addf5a0d0e8e8259205ae… ## $ xp_earned &lt;dbl&gt; 1408, 169, 3005, 465, 4023, 422, 539, 110, 1967, 428,… ## $ server_session &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… write_rds(xp, here(&quot;data/ea/xp.rds&quot;)) We sum up how many experience points a player got in total during the two weeks before the survey. xp &lt;- xp %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(date_time &gt;= (start_date - days(14))) %&gt;% group_by(player_id) %&gt;% summarise(xp = sum(xp_earned)) %&gt;% ungroup() 2.2.11 Process game time The raw game times were used in processing the other files, so we left processing it until here. First, we check which game sessions happened within the 14 days a participant took a survey (the file is already filtered to only include participants who actually filled out the survey). Afterwards, we aggregate the remaining game sessions per participant to get to how many hours they played in the two weeks before the survey (i.e., only aggregate/summarize game_sessions that happened within the past 14 days). game_time &lt;- game_time %&gt;% left_join(select(survey, player_id, start_date)) %&gt;% filter(game_start_time &gt;= (start_date - days(14))) %&gt;% select(player_id, game_start_time, game_end_time) %&gt;% mutate(duration = game_end_time-game_start_time) %&gt;% mutate(Hours = as.numeric(duration)/60/60) %&gt;% group_by(player_id) %&gt;% summarise(Hours = sum(Hours)) %&gt;% ungroup() 2.3 Merge survey and telemetry Next, we add the person-level aggregated telemetry variables to the survey data. The resulting data set will not deal with session level data, but summarizes, for each participant, their engagement in the 2 week observation period. First put all the aggregated telemetry into one data frame. telemetry &lt;- reduce( list(authentications, characters, friends, game_time, gestures, leveling, prestige, xp), left_join ) And then merge them to the survey. pvz &lt;- survey %&gt;% left_join(telemetry, by = &quot;player_id&quot;) 2.4 Exclusions First save a file with no exclusions. write_rds(pvz, here(&quot;data/ea/pvz.rds&quot;)) 2.4.1 Straightliners We take out all players who straightlined (gave the same response to every item) through SPANE and motivations scales. (If only SPANE items existed, then we didn’t exclude.) pvz &lt;- pvz %&gt;% mutate( straightliner = straightliner_spane &amp; straightliner_motivations ) pvz %&gt;% select(contains(&quot;straight&quot;)) %&gt;% group_by_all() %&gt;% count ## # A tibble: 4 x 4 ## # Groups: straightliner_spane, straightliner_motivations, straightliner [4] ## straightliner_spane straightliner_motivations straightliner n ## &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; ## 1 FALSE FALSE FALSE 507 ## 2 FALSE TRUE FALSE 4 ## 3 TRUE FALSE FALSE 6 ## 4 TRUE TRUE TRUE 1 pvz %&gt;% tabyl(straightliner) %&gt;% adorn_pct_formatting() ## straightliner n percent ## FALSE 517 99.8% ## TRUE 1 0.2% # filter() would also exclude NAs! pvz &lt;- filter(pvz, !straightliner | is.na(straightliner)) 2.4.2 Outliers Potential outliers. We replace all values that are more than 6SD away from the variable’s mean with NAs. As a consequence, individuals are excluded on an analysis-by-analysis case (so if has bad data relevant to that analysis or figure). This is only done for a subset of variables (relavant to analyses; see below). pvz &lt;- pvz %&gt;% # These variables will be affected pivot_longer( c(spane_1:xp, -played_with_others, -contains(&quot;straightliner&quot;)) ) %&gt;% group_by(name) %&gt;% mutate(z_value = as.numeric(scale(value))) These are the numbers of people taken out of each variable (only variables that were affected are shown): # This is what are taken out pvz %&gt;% summarise( Extremes = sum(abs(z_value&gt;=6), na.rm = TRUE), Extremes_p = percent(Extremes/n(), accuracy = .01) ) %&gt;% filter(Extremes &gt; 0) ## # A tibble: 12 x 3 ## name Extremes Extremes_p ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 critical_hit_count 1 0.19% ## 2 damage_dealt 1 0.19% ## 3 friends 2 0.39% ## 4 gestures 2 0.39% ## 5 Hours 1 0.19% ## 6 levelings 2 0.39% ## 7 score 2 0.39% ## 8 shots_fired 2 0.39% ## 9 shots_hit 1 0.19% ## 10 total_death_count 1 0.19% ## 11 total_kill_count 1 0.19% ## 12 xp 2 0.39% Code to do it: pvz &lt;- pvz %&gt;% mutate(value = ifelse(abs(z_value &gt;= 6), NA, value)) %&gt;% select(-z_value) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) %&gt;% ungroup() 2.5 Save files write_rds(pvz, here(&quot;data/ea/pvz-excluded.rds&quot;)) 2.6 Session info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 20.04.1 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 ## ## locale: ## [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 ## [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 ## [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.2 tibble_3.0.4 ggplot2_3.3.2 ## [9] tidyverse_1.3.0 anytime_0.3.9 janitor_2.0.1 scales_1.1.1 ## [13] lubridate_1.7.9.2 here_1.0.1 knitr_1.30 readxl_1.3.1 ## [17] pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.19 haven_2.3.1 snakecase_0.11.0 ## [5] colorspace_2.0-0 vctrs_0.3.5 generics_0.1.0 htmltools_0.5.0 ## [9] yaml_2.2.1 utf8_1.1.4 rlang_0.4.9 pillar_1.4.7 ## [13] withr_2.3.0 glue_1.4.2 DBI_1.1.0 dbplyr_2.0.0 ## [17] modelr_0.1.8 lifecycle_0.2.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_0.3.6 evaluate_0.14 labeling_0.4.2 ## [25] parallel_4.0.3 fansi_0.4.1 broom_0.7.2 Rcpp_1.0.5 ## [29] backports_1.2.1 jsonlite_1.7.2 farver_2.0.3 fs_1.5.0 ## [33] hms_0.5.3 digest_0.6.27 stringi_1.5.3 bookdown_0.21 ## [37] rprojroot_2.0.2 grid_4.0.3 cli_2.2.0 tools_4.0.3 ## [41] magrittr_2.0.1 crayon_1.3.4 pkgconfig_2.0.3 ellipsis_0.3.1 ## [45] xml2_1.3.2 reprex_0.3.0 rstudioapi_0.13 assertthat_0.2.1 ## [49] rmarkdown_2.6 httr_1.4.2 R6_2.5.0 compiler_4.0.3 "],["process-acnh-data.html", "3 Process AC:NH data 3.1 Raw data 3.2 Process raw files 3.3 Exclusions 3.4 Save files 3.5 Session info", " 3 Process AC:NH data Here, we process the AC:NH survey and telemetry files. We used the following R packages: library(pacman) p_load( readxl, knitr, here, lubridate, scales, janitor, tidyverse ) 3.1 Raw data This script expects the raw data files to be in data-raw/noa/. The raw telemetry and survey files are in a zip compressed file on OSF: https://osf.io/cjd6z/. Below, we provide code that downloads and unpacks these files. The raw survey data was edited to exclude test sessions, any data from individuals who did not consent / below 18, and some unnecessary variables, before uploading to OSF. The code to do that is shown below (but cannot be executed without our formr credentials) # Dont download if already downloaded if (!file.exists(here(&quot;data-raw/noa/formr-raw.rds&quot;))) { # Connect to formr formr::formr_connect() # These are the survey names on formr surveys &lt;- c(&quot;gaming_welcome&quot;, paste0(&quot;gaming_block&quot;, 2:5)) # Download data into a list of data frames ac &lt;- map(surveys, ~formr::formr_results(.) %&gt;% as_tibble) saveRDS(ac, here(&quot;data-raw/noa/formr-raw.rds&quot;)) } else {ac &lt;- readRDS(here(&quot;data-raw/noa/formr-raw.rds&quot;))} # Take out all intermediate time variables ac[[1]] &lt;- select(ac[[1]], -c(modified:expired)) ac[2:4] &lt;- map(ac[2:4], ~select(., -c(created:expired))) ac[[5]] &lt;- select(ac[[5]], -c(created, modified, expired)) # Transform to one data frame with one row per participant ac &lt;- ac %&gt;% reduce(left_join) # Limit data to survey window to exclude our test sessions ac &lt;- ac %&gt;% filter(created &gt;= ymd(&quot;2020-10-27&quot;)) %&gt;% filter(created &lt;= ymd(&quot;2020-10-27&quot;) + days(7)) range(ac$created) # Keep only surveys whose code exists and consents check out ac &lt;- filter( ac, !is.na(code), of_age==1, consent_data==1, consent==1 ) # Take out unnecessary variables ac &lt;- ac %&gt;% select( -c(session, browser, last_outside_referrer, of_age:consent) ) write_rds(ac, here(&quot;data-raw/noa/formr.rds&quot;)) The file produced by the above code chunk was uploaded to OSF in a zip compressed archive with the telemetry file. Start by downloading that file and unpacking it to the target directory by running the code below: file_dest &lt;- here(&quot;data-raw/noa/noa.zip&quot;) # Download &amp; extract file only if you haven&#39;t yet if (!file.exists(file_dest)) { download.file(&quot;https://osf.io/fev95/download&quot;, file_dest) } if (!file.exists(here(&quot;data-raw/noa/formr.rds&quot;))) { unzip(file_dest, exdir = here(&quot;data-raw/noa/&quot;)) } Next, we load the survey data file. ac &lt;- readRDS(here(&quot;data-raw/noa/formr.rds&quot;)) 3.2 Process raw files 3.2.1 Clean survey data Here, we clean the survey data. Specifically, we Harmonize names so that they are the same as in the other data set (i.e., from PvZ) Create duration variable for game time Give some sensible variable names Assign proper variable types # Harmonize some names to PvZ names ac &lt;- ac %&gt;% rename( gender = sex, gender_other = sex_other, player_id = code ) # Duration of survey ac &lt;- ac %&gt;% mutate( survey_duration = ended-created ) # Create variables for straightliners by checking if variance within a block of questions is zero ac$straightliner_spane &lt;- apply( select(ac, starts_with(&quot;spane_&quot;) &amp; !starts_with(&quot;spane_acnh&quot;)), 1, sd, na.rm = TRUE ) ac$straightliner_spane &lt;- ac$straightliner_spane==0 ac$straightliner_motivations &lt;- apply( select( ac, starts_with(&quot;autonomy_&quot;), starts_with(&quot;competence_&quot;), starts_with(&quot;related_&quot;), starts_with(&quot;enjoymen_&quot;), starts_with(&quot;extrinsic_&quot;) ), 1, sd, na.rm = TRUE ) ac$straightliner_motivations &lt;- ac$straightliner_motivations==0 # These are needed as factors ac &lt;- ac %&gt;% mutate(across(c(gender, played), as_factor)) # Reverse scored items ac &lt;- ac %&gt;% mutate( across( c( related_not_close, enjoyment_attention, enjoymen_boring ), ~ 8 - .x ) ) Next, let’s create mean indices for the scales like we did before. SPANE has positive affect, negative affect, and an affect balance score (subtract negative from positive). # Need to rename SPANE item so it doesnt become confused with scale score name ac &lt;- rename( ac, spane_positiveItem = spane_positive, spane_negativeItem = spane_negative ) # General SPANE ac &lt;- ac %&gt;% mutate( spane_positive = rowMeans( select( ., spane_positiveItem, spane_good, spane_pleasant, spane_happy, spane_joyful, spane_contented ), na.rm = TRUE ), spane_negative = rowMeans( select( ., spane_negativeItem, spane_bad, spane_unpleasant, spane_sad, spane_afraid, spane_angry ), na.rm = TRUE ), spane_balance = spane_positive - spane_negative ) # Motivations ac &lt;- ac %&gt;% mutate( autonomy = rowMeans( select(., starts_with(&quot;autonomy&quot;)), na.rm = TRUE ), competence = rowMeans( select(., starts_with(&quot;competence&quot;)), na.rm = TRUE ), relatedness = rowMeans( select(., starts_with(&quot;related&quot;)), na.rm = TRUE ), enjoyment = rowMeans( select(., starts_with(&quot;enjoymen&quot;)), na.rm = TRUE ), extrinsic = rowMeans( select(., starts_with(&quot;extrinsic&quot;)), na.rm = TRUE ) ) # SPANE because of playing AC:NH ac &lt;- ac %&gt;% mutate( spane_game_positive = rowMeans( select( ., spane_acnh_positive, spane_acnh_good, spane_acnh_pleasant, spane_acnh_happy, spane_acnh_joyful, spane_acnh_contented ), na.rm = TRUE ), spane_game_negative = rowMeans( select( ., spane_acnh_negative, spane_acnh_bad, spane_acnh_unpleasant, spane_acnh_sad, spane_acnh_afraid, spane_acnh_angry ), na.rm = TRUE ), spane_game_balance = spane_game_positive - spane_game_negative ) # Hours of estimated play ac &lt;- ac %&gt;% mutate(active_play_minutes = active_play_minutes / 60) %&gt;% mutate(active_play = rowSums(select(., starts_with(&quot;active_play&quot;)), na.rm = T)) 3.2.2 Checking First, we check how many rows per player there are. count(ac, player_id, sort = T) ## # A tibble: 5,987 x 2 ## player_id n ## &lt;chr&gt; &lt;int&gt; ## 1 &quot;&quot; 13 ## 2 &quot;7dadc6e88bc0b5b8&quot; 3 ## 3 &quot;33ec57527b06af7b&quot; 2 ## 4 &quot;48bb7bafae2e5c44&quot; 2 ## 5 &quot;49f5299432fef738&quot; 2 ## 6 &quot;5b9d217b3cbb39fa&quot; 2 ## 7 &quot;677ca59a6ed1e5a8&quot; 2 ## 8 &quot;7092634f86aa0992&quot; 2 ## 9 &quot;842b41d5e20f2922&quot; 2 ## 10 &quot;8bd8d7292b3a05b5&quot; 2 ## # … with 5,977 more rows There are two kinds of problems: No ID was captured An ID was used more than once For both cases, connecting to telemetry would be impossible (and wrong connections could be made in latter case), so we drop these cases. ac &lt;- add_count(ac, player_id) %&gt;% filter(n == 1) %&gt;% select(-n) 3.2.3 Telemetry This file is in the ZIP archive. gt &lt;- read_tsv(here(&quot;data-raw/noa/telem_data (since Sep 2020).txt&quot;)) Column definitions: lc_recorded_at = Session start date/time nc_recorded_at = Session end date/time hashed_id = Hashed account ID product_model = Switch model game was played on operation_mode = Identifies handheld mode, TV mode duration = Duration of session (seconds) storage_id = Whether game is played off game card, SD card or internal system memory application_id_hex = Game’s hashed ID We drop some unnecessary variables gt &lt;- select( gt, hashed_id, contains(&quot;recorded&quot;), duration ) Then rename names(gt) &lt;- c( &quot;player_id&quot;, &quot;session_start&quot;, &quot;session_end&quot;, &quot;Hours&quot; ) And turn duration into hours gt$Hours &lt;- gt$Hours/60/60 Assume that timestamps are US Pacific as this was used to report data collection dates &amp; times. gt &lt;- gt %&gt;% mutate( across(contains(&quot;session&quot;), ~mdy_hm(.x, tz = &quot;US/Pacific&quot;)) ) glimpse(gt) ## Rows: 191,498 ## Columns: 4 ## $ player_id &lt;chr&gt; &quot;be080cb5754884b3&quot;, &quot;35a6c680bcf65615&quot;, &quot;35a6c680bcf656… ## $ session_start &lt;dttm&gt; 2020-10-15 22:39:00, 2020-09-09 03:38:00, 2020-10-03 1… ## $ session_end &lt;dttm&gt; 2020-10-15 22:39:00, 2020-09-09 03:38:00, 2020-10-03 1… ## $ Hours &lt;dbl&gt; 0.67583333, 0.19111111, 0.67111111, 1.77750000, 1.76000… 3.2.4 Clean We don’t need to limit to IDs who took the survey as NOA has already done that–these data only contain folks who filled in the survey. We do need to limit the data to two weeks preceding the survey, and count session durations within that window. We therefore need to use the session start/end times to find out when the sessions happened. Some processing is required to do that as the times can have noise due to e.g. players’ system times being incorrectly set. Thus, many start times are the same (or even later) than the end time: gt %&gt;% mutate( later_or_same_start = session_start &gt;= session_end ) %&gt;% tabyl(later_or_same_start) %&gt;% adorn_pct_formatting() ## later_or_same_start n percent ## FALSE 13112 6.8% ## TRUE 178386 93.2% However, session durations are not based on the device time (session times): gt %&gt;% mutate( duration = as.numeric(session_end - session_start)/60/60 ) %&gt;% mutate(match = duration/60/60==Hours) %&gt;% tabyl(match) %&gt;% adorn_pct_formatting() ## match n percent ## FALSE 191494 100.0% ## TRUE 4 0.0% And end and start times should be within a window. tmp &lt;- gt %&gt;% filter( session_start &lt; ymd(&quot;2020-09-01&quot;) | session_end &lt; ymd(&quot;2020-09-01&quot;) | session_start &gt; ymd(&quot;2020-11-03&quot;) | session_end &gt; ymd(&quot;2020-11-03&quot;) ) %&gt;% arrange(session_start) %&gt;% mutate(player_id = fct_inorder(player_id)) # Proportion of these bad dates percent(nrow(tmp) / nrow(gt), .1) ## [1] &quot;3.1%&quot; We filter out sessions that aren’t in the two weeks preceding each player’s survey. Note not all survey respondents have telemetry so the resulting table will be longer # Get survey times from survey table gt &lt;- select(ac, player_id, created) %&gt;% left_join(gt) # Limit telemetry sessions to appropriate time window gt &lt;- gt %&gt;% filter(session_start &gt;= (created - days(14))) %&gt;% filter(session_start &lt; created) %&gt;% filter(session_end &lt; created) We then summarize to total hours per person. gt &lt;- gt %&gt;% group_by(player_id) %&gt;% summarise( Hours = sum(Hours), n_sessions = n() ) 3.2.5 Join survey and telemetry ac &lt;- left_join(ac, gt) 3.2.6 Checking People reported if they played AC:NH in the past 14 days. Lets summarise the players, number of players with telemetry, and mean hours, for these two groups ac %&gt;% group_by(played) %&gt;% summarise( Players = n(), Missing_Hours = sum(is.na(Hours)), Mean_Hours = mean(Hours, na.rm = TRUE) ) ## # A tibble: 3 x 4 ## played Players Missing_Hours Mean_Hours ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 I have played Animal Crossing: New Horizons … 4602 2017 11.7 ## 2 I have **NOT** played Animal Crossing: New H… 1233 1114 2.09 ## 3 &lt;NA&gt; 140 88 6.75 3.3 Exclusions First save a file with no exclusions. write_rds(ac, here(&quot;data/noa/ac.rds&quot;)) 3.3.1 Straightliners We take out all individuals who straightlined (gave the same response to every item) through SPANE and motivations scales. (If only SPANE items existed, then we didn’t exclude.) ac &lt;- ac %&gt;% mutate( straightliner = straightliner_spane &amp; straightliner_motivations ) ac %&gt;% select(contains(&quot;straight&quot;)) %&gt;% group_by_all() %&gt;% count ## # A tibble: 7 x 4 ## # Groups: straightliner_spane, straightliner_motivations, straightliner [7] ## straightliner_spane straightliner_motivations straightliner n ## &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; ## 1 FALSE FALSE FALSE 4266 ## 2 FALSE TRUE FALSE 7 ## 3 FALSE NA FALSE 1215 ## 4 TRUE FALSE FALSE 20 ## 5 TRUE TRUE TRUE 8 ## 6 TRUE NA NA 19 ## 7 NA NA NA 440 ac %&gt;% tabyl(straightliner) %&gt;% adorn_pct_formatting() ## straightliner n percent valid_percent ## FALSE 5508 92.2% 99.9% ## TRUE 8 0.1% 0.1% ## NA 459 7.7% - # filter() would also exclude NAs ac &lt;- filter(ac, !straightliner | is.na(straightliner)) 3.3.2 Outliers Potential outliers. We replace all values that are more than 6SD away from the variable’s mean with NAs. As a consequence, individuals are excluded on an analysis-by-analysis case (so if has bad data relevant to that analysis or figure). This is only done for a subset of variables (relavant to analyses; see below) ac &lt;- ac %&gt;% # These variables will be affected pivot_longer( c( spane_positiveItem:Hours, -played_with_others, -ended, -survey_duration, -contains(&quot;straightliner&quot;) ) ) %&gt;% group_by(name) %&gt;% mutate(z_value = as.numeric(scale(value))) These are the numbers of people taken out of each variable (only variables that were affected are shown): # This is what are taken out ac %&gt;% summarise( Extremes = sum(abs(z_value&gt;=6), na.rm = TRUE), Extremes_p = percent(Extremes/n(), accuracy = .01) ) %&gt;% filter(Extremes &gt; 0) ## # A tibble: 5 x 3 ## name Extremes Extremes_p ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 active_play 40 0.67% ## 2 active_play_hours 37 0.62% ## 3 Hours 12 0.20% ## 4 spane_acnh_afraid 25 0.42% ## 5 spane_game_negative 4 0.07% Code to do it: ac &lt;- ac %&gt;% mutate(value = ifelse(abs(z_value &gt;= 6), NA, value)) %&gt;% select(-z_value) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) %&gt;% ungroup() 3.4 Save files write_rds(ac, here(&quot;data/noa/ac-excluded.rds&quot;)) 3.5 Session info sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 20.04.1 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 ## ## locale: ## [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 ## [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 ## [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.2 tibble_3.0.4 ggplot2_3.3.2 ## [9] tidyverse_1.3.0 janitor_2.0.1 scales_1.1.1 lubridate_1.7.9.2 ## [13] here_1.0.1 knitr_1.30 readxl_1.3.1 pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.19 haven_2.3.1 snakecase_0.11.0 ## [5] colorspace_2.0-0 vctrs_0.3.5 generics_0.1.0 htmltools_0.5.0 ## [9] yaml_2.2.1 utf8_1.1.4 rlang_0.4.9 pillar_1.4.7 ## [13] withr_2.3.0 glue_1.4.2 DBI_1.1.0 dbplyr_2.0.0 ## [17] modelr_0.1.8 lifecycle_0.2.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_0.3.6 evaluate_0.14 parallel_4.0.3 ## [25] fansi_0.4.1 broom_0.7.2 Rcpp_1.0.5 backports_1.2.1 ## [29] jsonlite_1.7.2 fs_1.5.0 hms_0.5.3 digest_0.6.27 ## [33] stringi_1.5.3 bookdown_0.21 rprojroot_2.0.2 grid_4.0.3 ## [37] cli_2.2.0 tools_4.0.3 magrittr_2.0.1 crayon_1.3.4 ## [41] pkgconfig_2.0.3 ellipsis_0.3.1 xml2_1.3.2 reprex_0.3.0 ## [45] assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 rstudioapi_0.13 ## [49] R6_2.5.0 compiler_4.0.3 "],["describe-explore.html", "4 Describe &amp; explore 4.1 Demographics 4.2 Survey dates 4.3 Response rates 4.4 Missingness 4.5 Univariate figures 4.6 Correlation matrices 4.7 Plot studies combined 4.8 Create summary figure 4.9 Session info", " 4 Describe &amp; explore Here, we get the descriptive info for both studies that we report in the Method section of the paper. We used these packages: library(pacman) p_load( knitr, here, visdat, scales, patchwork, sjPlot, cowplot, janitor, ggbeeswarm, lemon, lubridate, tidyverse ) Then, we load the data sets. ac &lt;- read_rds(here(&quot;data/noa/ac-excluded.rds&quot;)) pvz &lt;- read_rds(here(&quot;data/ea/pvz-excluded.rds&quot;)) ac_full &lt;- read_rds(here(&quot;data/noa/ac.rds&quot;)) pvz_full &lt;- read_rds(here(&quot;data/ea/pvz.rds&quot;)) Join the two data sets. ac &lt;- ac %&gt;% select( player_id, gender, created, age, spane_balance, spane_positive, spane_negative, spane_game_balance, within_estimate, between_estimate, autonomy, competence, relatedness, enjoyment, extrinsic, active_play, Hours ) pvz &lt;- pvz %&gt;% select( player_id, gender, created = date, age, spane_balance, spane_positive, spane_negative, spane_game_balance, within_estimate, between_estimate, autonomy, competence, relatedness, enjoyment, extrinsic, active_play, Hours ) dat &lt;- bind_rows(pvz, ac, .id = &quot;Game&quot;) %&gt;% mutate(Game = factor(Game, labels = c(&quot;PvZ&quot;, &quot;AC:NH&quot;))) 4.1 Demographics In total, 6484 players responded to the survey. Their mean age was M = 31 with a standard deviation of SD = 10. Ages by study: dat %&gt;% group_by(Game) %&gt;% summarise( m_age = mean(age, na.rm = TRUE), s_age = sd(age, na.rm = TRUE), min_age = min(age, na.rm = TRUE), max_age = max(age, na.rm = TRUE) ) #&gt; # A tibble: 2 x 5 #&gt; Game m_age s_age min_age max_age #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; #&gt; 1 PvZ 34.9 11.8 18 99 #&gt; 2 AC:NH 30.9 9.68 18 99 Then let’s look at the sex distribution. tabyl(pvz, gender) %&gt;% adorn_pct_formatting() #&gt; gender n percent #&gt; Male 404 78.1% #&gt; Female 94 18.2% #&gt; Other 2 0.4% #&gt; Prefer not to say 17 3.3% tabyl(ac, gender) %&gt;% adorn_pct_formatting() #&gt; gender n percent valid_percent #&gt; Female 2462 41.3% 42.3% #&gt; Male 3124 52.4% 53.6% #&gt; Other 153 2.6% 2.6% #&gt; Prefer not to say 88 1.5% 1.5% #&gt; Item was never rendered for this user. 0 0.0% 0.0% #&gt; &lt;NA&gt; 140 2.3% - 4.2 Survey dates dat %&gt;% mutate(Date = as.Date(created)) %&gt;% count(Game, Date) %&gt;% kable() Game Date n PvZ 2020-08-11 69 PvZ 2020-08-12 9 PvZ 2020-08-13 7 PvZ 2020-08-15 1 PvZ 2020-08-16 1 PvZ 2020-08-17 1 PvZ 2020-08-18 1 PvZ 2020-08-20 1 PvZ 2020-08-21 1 PvZ 2020-08-23 1 PvZ 2020-08-28 1 PvZ 2020-09-24 320 PvZ 2020-09-25 64 PvZ 2020-09-26 21 PvZ 2020-09-27 12 PvZ 2020-09-28 5 PvZ 2020-09-29 2 AC:NH 2020-10-27 236 AC:NH 2020-10-28 4942 AC:NH 2020-10-29 450 AC:NH 2020-10-30 171 AC:NH 2020-10-31 57 AC:NH 2020-11-01 55 AC:NH 2020-11-02 56 4.3 Response rates # PvZ wave 1 p1 &lt;- nrow(pvz_full %&gt;% filter(date &lt; ymd(&quot;2020-09-01&quot;))) # PvZ wave 2 p2 &lt;- nrow(pvz_full %&gt;% filter(date &gt; ymd(&quot;2020-09-01&quot;))) # AC:NH a1 &lt;- nrow(ac) tibble( Game = c(&quot;PvZ w1&quot;, &quot;PvZ w2&quot;, &quot;AC:NH&quot;), Invitations = c(50000, 200000, 342825), Responses = c(p1, p2, a1), Rate = percent(Responses/Invitations, .01) ) #&gt; # A tibble: 3 x 4 #&gt; Game Invitations Responses Rate #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 PvZ w1 50000 94 0.19% #&gt; 2 PvZ w2 200000 424 0.21% #&gt; 3 AC:NH 342825 5967 1.74% How many individuals had telemetry foo &lt;- function(data) { data %&gt;% transmute(has_telemetry = !is.na(Hours)) %&gt;% tabyl(has_telemetry) %&gt;% adorn_pct_formatting() } map(list(pvz=pvz_full, ac=ac_full), foo) %&gt;% kable has_telemetry n percent FALSE 47 9.1% TRUE 471 90.9% has_telemetry n percent FALSE 3219 53.9% TRUE 2756 46.1% 4.4 Missingness vis_miss(pvz) vis_miss(ac) 4.5 Univariate figures This figure shows the distribution of well-being and motivation scores for both studies tmp &lt;- dat %&gt;% pivot_longer(c(spane_balance, autonomy:extrinsic)) tmp &lt;- tmp %&gt;% mutate( name = factor( name, levels = c( &quot;spane_balance&quot;, &quot;extrinsic&quot;, &quot;enjoyment&quot;, &quot;autonomy&quot;, &quot;competence&quot;, &quot;relatedness&quot; ), labels = c( &quot;Player well-being&quot;, &quot;Extrinsic motivation&quot;, &quot;Intrinsic motivation&quot;, &quot;Player autonomy&quot;, &quot;Player competence&quot;, &quot;Player relatedness&quot; ) ) ) tmp2 &lt;- tmp %&gt;% group_by(Game, name) %&gt;% summarise(value = mean(value, na.rm = TRUE)) filter(tmp, Game == &quot;PvZ&quot;) %&gt;% ggplot(aes(value, col = Game, fill = Game)) + coord_cartesian(ylim = c(-1, 1)) + scale_color_manual( values = rev(colors), aesthetics = c(&quot;color&quot;, &quot;fill&quot;), guide = guide_legend(reverse = TRUE) ) + geom_histogram( aes(y = stat(ncount)), col = &quot;white&quot;, bins = 20 ) + geom_histogram( data = filter(tmp, Game == &quot;AC:NH&quot;), aes(y = stat(ncount)*-1), col = &quot;white&quot;, bins = 20 ) + scale_y_continuous( breaks = c(-1, -.5, 0, .5, 1), labels = c(1, .5, 0, .5, 1) ) + scale_x_continuous(&quot;Value&quot;, breaks = pretty_breaks()) + geom_point( data = tmp2, aes(y = -1.01), shape = 25, size = 2.5 ) + # Make sure 1 is shown on all figures by drawing a blank geom geom_blank(data = tibble(Game = &quot;PvZ&quot;, value = 1)) + labs(y = &quot;Normalized count&quot;) + facet_wrap(&quot;name&quot;, scales = &quot;free&quot;) + theme(axis.title.x = element_blank(), legend.position = &quot;right&quot;) And then a summary figure of the times, subjective and objective. Means indicate means over participants who had both measures. # Histograms show all participants tmp &lt;- dat %&gt;% select(Game, Hours, active_play) %&gt;% pivot_longer(-Game) %&gt;% mutate(name = ifelse(name==&quot;Hours&quot;, &quot;Hours&quot;, &quot;Estimated&quot;)) %&gt;% mutate(Game2 = str_glue(&quot;{Game} ({name})&quot;)) # Summaries over people who had both metrics tmp2 &lt;- dat %&gt;% select(Game, Hours, active_play) %&gt;% drop_na(active_play, Hours) %&gt;% pivot_longer(-Game) %&gt;% mutate(name = ifelse(name==&quot;Hours&quot;, &quot;Hours&quot;, &quot;Estimated&quot;)) %&gt;% mutate(Game2 = str_glue(&quot;{Game} ({name})&quot;)) %&gt;% group_by(Game, Game2, name) %&gt;% summarise(m = mean(value, na.rm = TRUE), n = n()) # This is really complicated because of the legend tmp %&gt;% ggplot(aes(fill = Game2, alpha = Game2)) + # Use two variables to control facets and colors/alpha # Such that legend is constructed appropriately scale_fill_manual( values = rep(rev(colors), each = 2), guide = guide_legend(reverse = TRUE) ) + scale_alpha_manual( values = c(.4, 1, .4, 1), guide = guide_legend(reverse = TRUE) ) + scale_y_continuous( breaks = c(-1, -.5, 0, .5, 1), labels = c(1, .5, 0, .5, 1), expand = expansion(.015) ) + scale_x_continuous(breaks = pretty_breaks(7)) + coord_cartesian(ylim = c(-1, 1), xlim = c(0, 80)) + labs(x = &quot;Hours&quot;, y = &quot;Normalized count&quot;) + # Use different geoms to pick appropriate variables geom_histogram( data = filter(tmp, name==&quot;Hours&quot;), aes(x = value, y = stat(ncount)), bins = 80, col = &quot;white&quot; ) + geom_histogram( data = filter(tmp, name==&quot;Estimated&quot;), aes(x = value, y = stat(ncount) * -1), bins = 80, col = &quot;white&quot; ) + geom_point( data = filter(tmp2, name==&quot;Hours&quot;), aes(x = m, y = -0.97), shape = 25, size = 2.5, show.legend = FALSE, col = &quot;white&quot; ) + geom_point( data = filter(tmp2, name==&quot;Estimated&quot;), aes(x = m, y = -0.97), shape = 25, size = 2.5, alpha = 0.5, show.legend = FALSE, col = &quot;white&quot; ) + facet_rep_wrap(&quot;Game&quot;, scales = &quot;fixed&quot;, nrow = 2) + theme( strip.text = element_blank(), legend.position = &quot;right&quot;, legend.title = element_blank() ) # Summary of values truncated from graph dat %&gt;% group_by(Game) %&gt;% summarise( across( active_play:Hours, list( n = ~sum(!is.na(.x)), x = ~sum(.x&gt;80, na.rm = TRUE), p = ~percent(sum(.x&gt;80, na.rm = TRUE) / sum(!is.na(.x)), .01) ) ) ) #&gt; # A tibble: 2 x 7 #&gt; Game active_play_n active_play_x active_play_p Hours_n Hours_x Hours_p #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 PvZ 517 0 0.00% 469 0 0.00% #&gt; 2 AC:NH 5927 58 0.98% 2737 7 0.26% dat %&gt;% group_by(Game) %&gt;% summarise( across( active_play:Hours, ~max(.x, na.rm = T) ) ) #&gt; # A tibble: 2 x 3 #&gt; Game active_play Hours #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 PvZ 41.0 69.3 #&gt; 2 AC:NH 161. 99.8 4.6 Correlation matrices cormat &lt;- function(data, title) { data %&gt;% rename_all(str_to_title) %&gt;% psych::cor.plot( scale = FALSE, stars = TRUE, xlas = 2, show.legend = FALSE, main = str_glue(&quot;{title} correlation matrix&quot;), ) } select(pvz, where(is.numeric)) %&gt;% cormat(&quot;PvZ&quot;) select(ac, where(is.numeric)) %&gt;% cormat(&quot;AC:NH&quot;) Then we will draw scatterplot matrices, with this custom function: lm_function &lt;- function( data, mapping, ... ){ p &lt;- ggplot( data = data, mapping = mapping ) + geom_point( color = &quot;#56B4E9&quot;, alpha = 0.5 ) + geom_smooth( method=lm, fill=&quot;#0072B2&quot;, color=&quot;#0072B2&quot;, ...) p } dens_function &lt;- function( data, mapping, ... ){ p &lt;- ggplot( data = data, mapping = mapping ) + geom_density(fill = &quot;#009E73&quot;, color = NA, alpha = 0.5) } pair_plot &lt;- function( dat ) { GGally::ggpairs( data = dat, lower = list(continuous = lm_function), # custom helper function diag = list(continuous = dens_function), # custom helper function ) + theme( axis.line=element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(), axis.ticks=element_blank(), axis.title.y=element_blank(), axis.title.x=element_blank(), legend.position=&quot;none&quot;, panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), strip.background = element_blank() ) } 4.6.1 Well-being &amp; motivations correlations Let’s have a look at the correlations between the concepts of well-being and motivations (aggregated). # call the function pair_plot( dat%&gt;% select( spane_balance:extrinsic, spane_game_balance ) ) 4.6.2 More well-being correlations Then correlations between well-being, autonomy motivation, enjoyment, and extrinsic motivation. pair_plot( dat %&gt;% select( autonomy, extrinsic, enjoyment, spane_balance, spane_game_balance ) ) Next relations between self-estimated play (effects) and well-being. pair_plot( dat %&gt;% select( Hours, active_play, within_estimate, between_estimate, spane_balance, spane_game_balance ) ) 4.7 Plot studies combined Then, let’s plot and describe demographic information. The plots in this section will be for both studies combined. # raincloud plot function from https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R # Defining the geom_flat_violin function ---- # Note: the below code modifies the # existing github page by removing a parenthesis in line 50 &quot;%||%&quot; &lt;- function(a, b) { if (!is.null(a)) a else b } geom_flat_violin &lt;- function(mapping = NULL, data = NULL, stat = &quot;ydensity&quot;, position = &quot;dodge&quot;, trim = TRUE, scale = &quot;area&quot;, show.legend = NA, inherit.aes = TRUE, ...) { layer( data = data, mapping = mapping, stat = stat, geom = GeomFlatViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list( trim = trim, scale = scale, ... ) ) } #&#39; @rdname ggplot2-ggproto #&#39; @format NULL #&#39; @usage NULL #&#39; @export GeomFlatViolin &lt;- ggproto(&quot;GeomFlatViolin&quot;, Geom, setup_data = function(data, params) { data$width &lt;- data$width %||% params$width %||% (resolution(data$x, FALSE) * 0.9) # ymin, ymax, xmin, and xmax define the bounding rectangle for each group data %&gt;% group_by(group) %&gt;% mutate( ymin = min(y), ymax = max(y), xmin = x, xmax = x + width / 2 ) }, draw_group = function(data, panel_scales, coord) { # Find the points for the line to go all the way around data &lt;- transform(data, xminv = x, xmaxv = x + violinwidth * (xmax - x) ) # Make sure it&#39;s sorted properly to draw the outline newdata &lt;- rbind( plyr::arrange(transform(data, x = xminv), y), plyr::arrange(transform(data, x = xmaxv), -y) ) # Close the polygon: set first and last point the same # Needed for coord_polar and such newdata &lt;- rbind(newdata, newdata[1, ]) ggplot2:::ggname(&quot;geom_flat_violin&quot;, GeomPolygon$draw_panel(newdata, panel_scales, coord)) }, draw_key = draw_key_polygon, default_aes = aes( weight = 1, colour = &quot;grey20&quot;, fill = &quot;white&quot;, size = 0.5, alpha = NA, linetype = &quot;solid&quot; ), required_aes = c(&quot;x&quot;, &quot;y&quot;) ) # function that returns summary stats describe &lt;- function( dat, variable, trait = FALSE ){ # if variable is not repeated-measures, take only one measure per participant if (trait == TRUE){ dat &lt;- dat %&gt;% group_by(player_id) %&gt;% slice(1) %&gt;% ungroup() } # then get descriptives descriptives &lt;- dat %&gt;% filter(!is.na(UQ(sym(variable)))) %&gt;% # remove missing values summarise( across( !! variable, list( N = ~ n(), mean = mean, sd = sd, median = median, min = min, max = max, cilow = ~Rmisc::CI(.x)[[3]], # lower CI cihigh = ~Rmisc::CI(.x)[[1]] # upper CI ) ) ) descriptives &lt;- descriptives %&gt;% # only keep measure rename_all( ~ str_remove( ., paste0(variable, &quot;_&quot;) ) ) %&gt;% mutate( variable = variable, range = max - min ) %&gt;% relocate(variable) %&gt;% relocate( range, .after = max ) return(descriptives) } single_cloud &lt;- function( raw_data, summary_data, variable, color, title, trait = FALSE ){ # take only one row per person if it&#39;s a trait variable if (trait == TRUE){ raw_data &lt;- raw_data %&gt;% group_by(player_id) %&gt;% slice(1) %&gt;% ungroup() } # the plot p &lt;- ggplot( raw_data %&gt;% mutate(Density = 1), aes( x = Density, y = get(variable) ) ) + geom_flat_violin( # the &quot;cloud&quot; position = position_nudge(x = .2, y = 0), adjust = 2, color = NA, fill = color, alpha = 0.5 ) + geom_point( # the &quot;rain&quot; position = position_jitter(width = .15), size = 1, color = color, alpha = 0.5 ) + geom_point( # the mean from the summary stats data = summary_data %&gt;% filter(variable == !! variable) %&gt;% mutate(Density = 1), aes( x = Density + 0.175, y = mean ), color = color, size = 2.5 ) + geom_errorbar( # error bars data = summary_data %&gt;% filter(variable == !! variable) %&gt;% mutate(Density = 1), aes( x = Density + 0.175, y = mean, ymin = cilow, ymax = cihigh ), width = 0, size = 0.8, color = color ) + ylab(title) + theme_cowplot() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.line = element_blank() ) + guides( color = FALSE, fill = FALSE ) + coord_flip() return(p) } single_cloud( dat, describe(dat, &quot;age&quot;, trait = FALSE), &quot;age&quot;, &quot;#009E73&quot;, &quot;Distribution of age&quot; ) And a check of the variable distributions. p1 &lt;- single_cloud( pvz, describe(pvz, &quot;spane_balance&quot;, trait = TRUE), &quot;spane_balance&quot;, &quot;#56B4E9&quot;, title = &quot;SPANE Balance&quot;, trait = TRUE ) p2 &lt;- single_cloud( pvz, describe(pvz, &quot;autonomy&quot;, trait = TRUE), &quot;autonomy&quot;, &quot;#009E73&quot;, title = &quot;Autonomy&quot;, trait = TRUE ) p3 &lt;- single_cloud( pvz, describe(pvz, &quot;competence&quot;, trait = TRUE), &quot;competence&quot;, &quot;#F0E442&quot;, title = &quot;Competence&quot;, trait = TRUE ) p4 &lt;- single_cloud( pvz, describe(pvz, &quot;relatedness&quot;, trait = TRUE), &quot;relatedness&quot;, &quot;#000000&quot;, title = &quot;Relatedness&quot;, trait = TRUE ) p5 &lt;- single_cloud( pvz, describe(pvz, &quot;enjoyment&quot;, trait = TRUE), &quot;enjoyment&quot;, &quot;#0072B2&quot;, title = &quot;Enjoyment&quot;, trait = TRUE ) p6 &lt;- single_cloud( pvz, describe(pvz, &quot;extrinsic&quot;, trait = TRUE), &quot;extrinsic&quot;, &quot;#D55E00&quot;, title = &quot;Extrinsic motivation&quot;, trait = TRUE ) p7 &lt;- single_cloud( pvz, describe(pvz, &quot;active_play&quot;, trait = TRUE), &quot;active_play&quot;, &quot;#CC79A7&quot;, title = &quot;Self-estimated play&quot;, trait = TRUE ) (p1 | p2) / (p3 | p4) / (p5 | p6) / p7 4.8 Create summary figure Alright, here I’ll create a summary figure that shows a beeswarm plot for each of the variables we’re interested in. First, because we’ll plot per measure, let’s turn the data into the long format. dat_long &lt;- dat %&gt;% pivot_longer( spane_balance:Hours, names_to = &quot;Variable&quot;, values_to = &quot;value&quot; ) %&gt;% mutate(Variable = as.factor(Variable)) Now, let’s get summary stats for each measure. # function to get summary stats get_summary &lt;- function( dat ) { summary_stats &lt;- dat %&gt;% group_by(Game) %&gt;% summarise( across( spane_balance:Hours, list( N = ~ sum(!is.na(.x)), Mean = ~ mean(.x, na.rm = TRUE), SD = ~ sd(.x, na.rm = TRUE), Median = ~ median(.x, na.rm = TRUE), Min = ~ min(.x, na.rm = TRUE), Max = ~ max(.x, na.rm = TRUE), `Lower 95%CI` = ~Rmisc::CI(na.omit(.x))[[3]], # lower CI `Upper 95%CI` = ~Rmisc::CI(na.omit(.x))[[1]] ) ) ) %&gt;% # get into long format pivot_longer( -Game, names_to = c(&quot;Variable&quot;, &quot;Measure&quot;), values_to = &quot;Value&quot;, names_pattern = &quot;(.*)_([^_]+$)&quot; # match by last occurrence of underscore ) %&gt;% # and back to wide format pivot_wider( id_cols = c(Game, Variable), names_from = Measure, values_from = Value ) return(summary_stats) } summary_stats &lt;- get_summary(dat) # rename both so that we have the same order of factor levels for the figure rename_and_relevel &lt;- function( dat ) { dat &lt;- dat %&gt;% mutate( Variable = fct_relevel( Variable, &quot;SPANE&quot; = &quot;spane_balance&quot;, &quot;Hours&quot;, &quot;active_play&quot;, &quot;autonomy&quot;, &quot;competence&quot;, &quot;relatedness&quot;, &quot;enjoyment&quot;, &quot;extrinsic&quot; ), Variable = fct_recode( Variable, &quot;Affective well-being&quot; = &quot;spane_balance&quot;, &quot;Objective play time&quot; = &quot;Hours&quot;, &quot;Self-reported play time&quot; = &quot;active_play&quot;, &quot;Autonomy&quot; = &quot;autonomy&quot;, &quot;Competence&quot; = &quot;competence&quot;, &quot;Relatedness&quot; = &quot;relatedness&quot;, &quot;Enjoyment&quot; = &quot;enjoyment&quot;, &quot;Extrinsic&quot; = &quot;extrinsic&quot; ) ) return(dat) } dat_long &lt;- rename_and_relevel(dat_long) summary_stats &lt;- rename_and_relevel(summary_stats) And then the beeswarm plots. summary_stats &lt;- summary_stats %&gt;% group_by(Variable) %&gt;% mutate( # the position of geom_text x = max(Max) * 0.85, across( c(Mean, SD), ~ format(round(.x, digits = 1), nsmall = 1) ) ) # a function because we &quot;split&quot; up the plot with patchwork beeswarm_plots &lt;- function( dat, subset, mean_position, sd_position, col_font_size, row_font_size ){ ggplot( dat %&gt;% filter( Variable %in% subset ), aes( x = value, y = 1, color = Game ) ) + geom_quasirandom( size = 1, groupOnX = FALSE, shape = 1, alpha = 0.8 ) + facet_grid( Game ~ Variable, scales = &quot;free_x&quot; ) + geom_text( data = summary_stats %&gt;% filter(Variable %in% subset), aes( x = x, y = mean_position, label = paste0(&quot;M = &quot;, Mean) ), color = &quot;black&quot;, size = 2.5 ) + geom_text( data = summary_stats %&gt;% filter(Variable %in% subset), aes( x = x, y = sd_position, label = paste0(&quot;SD = &quot;, SD) ), color = &quot;black&quot;, size = 2.5 ) + facet_rep_grid( Game ~ Variable, scales = &quot;free_x&quot; ) + scale_color_manual(values=c(&quot;navyblue&quot;, &quot;#E60012&quot;)) + theme( axis.text.y = element_blank(), axis.title.x = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line = element_line(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), strip.background.x = element_blank(), strip.background.y = element_blank(), strip.text.x = element_text(size = col_font_size), strip.text.y = element_text(size = row_font_size), legend.position = &quot;none&quot; ) -&gt; p return(p) } p1 &lt;- beeswarm_plots( dat_long, c(&quot;Competence&quot;, &quot;Relatedness&quot;, &quot;Enjoyment&quot;, &quot;Extrinsic&quot;, &quot;Autonomy&quot;), 1.65, 1.5, 10, 11 ) p2 &lt;- beeswarm_plots( dat_long, c(&quot;Affective well-being&quot;, &quot;Objective play time&quot;, &quot;Self-reported play time&quot;), 2.0, 1.8, 10, 11 ) p2 / p1 4.9 Session info sessionInfo() #&gt; R version 4.0.3 (2020-10-10) #&gt; Platform: x86_64-pc-linux-gnu (64-bit) #&gt; Running under: Ubuntu 20.04.1 LTS #&gt; #&gt; Matrix products: default #&gt; BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 #&gt; LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 #&gt; #&gt; locale: #&gt; [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 #&gt; [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 #&gt; [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C #&gt; [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 #&gt; [5] readr_1.4.0 tidyr_1.1.2 tibble_3.0.4 tidyverse_1.3.0 #&gt; [9] lubridate_1.7.9.2 lemon_0.4.5 ggbeeswarm_0.6.0 ggplot2_3.3.2 #&gt; [13] janitor_2.0.1 cowplot_1.1.0 sjPlot_2.8.6 patchwork_1.1.0 #&gt; [17] scales_1.1.1 visdat_0.5.3 here_1.0.1 knitr_1.30 #&gt; [21] pacman_0.5.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-150 fs_1.5.0 insight_0.11.1 httr_1.4.2 #&gt; [5] rprojroot_2.0.2 tools_4.0.3 backports_1.2.1 utf8_1.1.4 #&gt; [9] R6_2.5.0 sjlabelled_1.1.7 vipor_0.4.5 DBI_1.1.0 #&gt; [13] colorspace_2.0-0 withr_2.3.0 mnormt_2.0.2 tidyselect_1.1.0 #&gt; [17] gridExtra_2.3 emmeans_1.5.3 compiler_4.0.3 cli_2.2.0 #&gt; [21] performance_0.6.1 rvest_0.3.6 xml2_1.3.2 sandwich_3.0-0 #&gt; [25] labeling_0.4.2 bookdown_0.21 bayestestR_0.8.0 psych_2.0.9 #&gt; [29] mvtnorm_1.1-1 digest_0.6.27 minqa_1.2.4 rmarkdown_2.6 #&gt; [33] pkgconfig_2.0.3 htmltools_0.5.0 lme4_1.1-26 highr_0.8 #&gt; [37] dbplyr_2.0.0 Rmisc_1.5 rlang_0.4.9 readxl_1.3.1 #&gt; [41] rstudioapi_0.13 farver_2.0.3 generics_0.1.0 zoo_1.8-8 #&gt; [45] jsonlite_1.7.2 magrittr_2.0.1 parameters_0.10.1 Matrix_1.2-18 #&gt; [49] fansi_0.4.1 Rcpp_1.0.5 munsell_0.5.0 lifecycle_0.2.0 #&gt; [53] stringi_1.5.3 multcomp_1.4-15 yaml_2.2.1 snakecase_0.11.0 #&gt; [57] MASS_7.3-53 plyr_1.8.6 grid_4.0.3 parallel_4.0.3 #&gt; [61] sjmisc_2.8.5 crayon_1.3.4 lattice_0.20-41 ggeffects_1.0.1 #&gt; [65] haven_2.3.1 splines_4.0.3 sjstats_0.18.0 hms_0.5.3 #&gt; [69] tmvnsim_1.0-2 pillar_1.4.7 boot_1.3-25 estimability_1.3 #&gt; [73] effectsize_0.4.1 codetools_0.2-18 reprex_0.3.0 glue_1.4.2 #&gt; [77] evaluate_0.14 modelr_0.1.8 vctrs_0.3.5 nloptr_1.2.2.2 #&gt; [81] cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1 xfun_0.19 #&gt; [85] xtable_1.8-4 broom_0.7.2 coda_0.19-4 survival_3.2-7 #&gt; [89] beeswarm_0.2.3 statmod_1.4.35 TH.data_1.0-10 ellipsis_0.3.1 "],["analyses.html", "5 Analyses 5.1 Create joint dataset 5.2 RQ1: Time and well-being 5.3 RQ2: Well-being and motivation 5.4 Nonlinear models 5.5 System information", " 5 Analyses library(pacman) p_load( here, knitr, patchwork, scales, broom, ggstance, tidyverse ) theme_set( theme_classic(base_line_size = .25, base_rect_size = 0) + theme( strip.text = element_text(size = rel(1)), strip.background = element_blank(), legend.position = &quot;right&quot; ) ) colors &lt;- c(&quot;navyblue&quot;, &quot;#E60012&quot;) ac &lt;- read_rds(here(&quot;data/noa/ac-excluded.rds&quot;)) pvz &lt;- read_rds(here(&quot;data/ea/pvz-excluded.rds&quot;)) ac2 &lt;- read_rds(here(&quot;data/noa/ac.rds&quot;)) pvz2 &lt;- read_rds(here(&quot;data/ea/pvz.rds&quot;)) 5.1 Create joint dataset Create harmonized datasets for easier analysis ac &lt;- ac %&gt;% select( player_id, spane_balance, autonomy, competence, relatedness, enjoyment, extrinsic, active_play, Hours ) pvz &lt;- pvz %&gt;% select( player_id, spane_balance, autonomy, competence, relatedness, enjoyment, extrinsic, active_play, Hours ) dat &lt;- bind_rows(pvz, ac, .id = &quot;Game&quot;) %&gt;% mutate(Game = factor(Game, labels = c(&quot;PvZ&quot;, &quot;AC:NH&quot;))) Game time is in units of 10 hours to make the size of the coefficients bigger and thus easier to interpret e.g. when shown with 2 decimal points. dat$Hours10 &lt;- dat$Hours / 10 dat$active_play10 &lt;- dat$active_play / 10 5.2 RQ1: Time and well-being 5.2.1 Objective vs subjective game time Describe subjective and objective time difference. These numbers are a bit confusing because the means include everyone, but difference only those who had both values (so cannot compute differences from means) dat %&gt;% group_by(Game) %&gt;% mutate(difference = active_play-Hours) %&gt;% summarise( across( c(Hours, active_play, difference), list(m = ~mean(.x, na.rm = T), s = ~sd(.x, na.rm = T)) ) ) #&gt; # A tibble: 2 x 7 #&gt; Game Hours_m Hours_s active_play_m active_play_s difference_m difference_s #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 PvZ 8.35 11.4 9.77 9.96 1.59 11.8 #&gt; 2 AC:NH 10.6 12.7 8.94 15.0 0.459 15.8 p0 &lt;- dat %&gt;% ggplot(aes(Hours, active_play, col = Game)) + scale_color_manual(values = colors) + geom_point(shape = 1, alpha = .5, size = .5) + scale_y_continuous(breaks = pretty_breaks()) + scale_x_continuous(breaks = pretty_breaks()) + geom_smooth(method = &quot;lm&quot;, col = &quot;black&quot;, size = .5, alpha = .25) + theme(aspect.ratio = 1) + guides( color = guide_legend( override.aes = list(size = 3, shape = 16, alpha = 1) ) ) + facet_wrap(&quot;Game&quot;, scales = &quot;free&quot;, nrow = 2) p1 &lt;- p0 + geom_abline(lty = 2, size = .25) Model fitted separately to both datasets res &lt;- function(model) { out1 &lt;- tidy(model, conf.int = TRUE) %&gt;% select(-statistic) %&gt;% rename(SE = std.error) out2 &lt;- glance(model) %&gt;% select(1,2, nobs) %&gt;% rename(r2 = r.squared, r2a = adj.r.squared) bind_cols(out1, out2) } dat %&gt;% group_by(Game) %&gt;% group_modify(~res(lm(active_play ~ Hours, data = .x))) %&gt;% kable(digits = c(0,2,2,1,3,2,2,2,2,1)) Game term estimate SE p.value conf.low conf.high r2 r2a nobs PvZ (Intercept) 7.09 0.5 0 6.06 8.12 0.15 0.15 469 PvZ Hours 0.34 0.0 0 0.27 0.41 0.15 0.15 469 AC:NH (Intercept) 5.84 0.4 0 5.13 6.55 0.16 0.16 2714 AC:NH Hours 0.49 0.0 0 0.45 0.54 0.16 0.16 2714 5.2.2 Objective time and SWB p2 &lt;- p0 + aes(y = spane_balance) Model fitted separately to both datasets dat %&gt;% group_by(Game) %&gt;% group_modify(~res(lm(scale(spane_balance) ~ Hours10, data = .x))) %&gt;% kable(digits = c(0,2,2,1,3,2,2,2,2,1)) Game term estimate SE p.value conf.low conf.high r2 r2a nobs PvZ (Intercept) -0.07 0.1 0.200 -0.19 0.04 0.01 0.01 468 PvZ Hours10 0.10 0.0 0.017 0.02 0.18 0.01 0.01 468 AC:NH (Intercept) -0.03 0.0 0.239 -0.08 0.02 0.01 0.01 2537 AC:NH Hours10 0.06 0.0 0.000 0.03 0.09 0.01 0.01 2537 A separate figure of just this foo &lt;- function(game, n) { tmp &lt;- dat %&gt;% mutate(Game2 = factor(Game, labels = c(&quot;Plants vs. Zombies: Battle for Neighborville&quot;, &quot;Animal Crossing: New Horizons&quot;))) %&gt;% filter(Game == game) tmp %&gt;% ggplot(aes(Hours, spane_balance)) + geom_point(alpha = .5, size = 1.75, color = colors[n]) + scale_y_continuous( &quot;Player wellbeing&quot;, breaks = pretty_breaks() ) + scale_x_continuous( str_glue(&quot;Hours played\\n{unique(tmp$Game2)}&quot;), breaks = pretty_breaks() ) + geom_smooth( method = &quot;lm&quot;, size = .75, alpha = .2, col = colors[n], fill = colors[n] ) + theme(aspect.ratio = 1, legend.position = &quot;none&quot;, strip.text = element_blank()) + facet_wrap(&quot;Game2&quot;, scales = &quot;free&quot;, nrow = 1) } foo(&quot;PvZ&quot;, 1) | foo(&quot;AC:NH&quot;, 2) 5.2.3 Subjective time and SWB p3 &lt;- p0 + aes(x = active_play, y = spane_balance) dat %&gt;% group_by(Game) %&gt;% group_modify(~res(lm(scale(spane_balance) ~ active_play10, data = .x))) %&gt;% kable(digits = c(0,2,2,1,3,2,2,2,2,1)) Game term estimate SE p.value conf.low conf.high r2 r2a nobs PvZ (Intercept) -0.05 0.1 0.433 -0.17 0.07 0.00 0.00 516 PvZ active_play10 0.05 0.0 0.264 -0.04 0.14 0.00 0.00 516 AC:NH (Intercept) -0.07 0.0 0.000 -0.10 -0.04 0.01 0.01 5487 AC:NH active_play10 0.07 0.0 0.000 0.05 0.08 0.01 0.01 5487 5.2.4 Figure (p1 + labs(x = &quot;Hours played&quot;, y = &quot;Estimated hours&quot;) + theme(legend.position = &quot;none&quot;) | p2 + labs(x = &quot;Hours played&quot;, y = &quot;Well-being&quot;) + theme(legend.position = &quot;none&quot;) | p3 + labs(x = &quot;Estimated hours&quot;, y = &quot;Well-being&quot;) + theme(legend.position = &quot;right&quot;) ) &amp; plot_annotation(tag_levels = &quot;A&quot;) &amp; theme(strip.text = element_blank()) 5.3 RQ2: Well-being and motivation # Nice names for plots dat &lt;- dat %&gt;% rename_all(str_to_title) dat &lt;- dat %&gt;% rename(Intrinsic = Enjoyment) # Standardize everything # Hours (centered) is divided by 10 to put on same scale with others. dat &lt;- dat %&gt;% group_by(Game) %&gt;% mutate( across(Spane_balance:Extrinsic, ~as.numeric(scale(., T, T))), Hours = as.numeric(scale(Hours10, T, F)) ) # Fit all models to both datasets xs &lt;- dat %&gt;% group_by(Game) %&gt;% nest() %&gt;% mutate( # Omnibus model where variables work together x = map(data, ~lm(Spane_balance ~ (Autonomy + Competence + Relatedness + Intrinsic + Extrinsic) * Hours, data = .x)), # Separate models for variables to work alone x1 = map(data, ~lm(Spane_balance ~ Autonomy * Hours, data = .x)), x2 = map(data, ~lm(Spane_balance ~ Competence * Hours, data = .x)), x3 = map(data, ~lm(Spane_balance ~ Relatedness * Hours, data = .x)), x4 = map(data, ~lm(Spane_balance ~ Intrinsic * Hours, data = .x)), x5 = map(data, ~lm(Spane_balance ~ Extrinsic * Hours, data = .x)) ) tmp &lt;- xs %&gt;% pivot_longer(x:x5, names_to = &quot;Model&quot;) %&gt;% mutate(Model = ifelse(Model==&quot;x&quot;, &#39;Omnibus&#39;, &#39;Unique&#39;)) %&gt;% mutate(out = map(value, ~tidy(., conf.int = TRUE))) %&gt;% unnest(out) %&gt;% filter(!(term %in% c(&#39;(Intercept)&#39;))) %&gt;% mutate(term = fct_rev(fct_inorder(term))) %&gt;% mutate( Type = factor( str_detect(term, &quot;:&quot;), labels = c(&quot;Main effect&quot;, &quot;Moderation&quot;) ) ) p1 &lt;- tmp %&gt;% filter(Model == &quot;Omnibus&quot;) %&gt;% drop_na() %&gt;% ggplot(aes(estimate, term, col = Game)) + scale_color_manual(values = colors) + scale_x_continuous( &#39;Regression coefficient&#39;, breaks = pretty_breaks() ) + geom_vline(xintercept = 0, lty = 2, size = .2) + geom_pointrangeh( aes(xmin = conf.low, xmax = conf.high), size = .4, position = position_dodge2v(.4) ) + theme( axis.title.y = element_blank(), strip.text = element_blank() ) p1 map(xs$x, res) #&gt; [[1]] #&gt; # A tibble: 12 x 9 #&gt; term estimate SE p.value conf.low conf.high r2 r2a nobs #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 (Intercept) 0.0162 0.0428 7.06e-1 -0.0680 0.100 0.291 0.272 404 #&gt; 2 Autonomy 0.285 0.0650 1.55e-5 0.157 0.412 0.291 0.272 404 #&gt; 3 Competence 0.0255 0.0557 6.48e-1 -0.0840 0.135 0.291 0.272 404 #&gt; 4 Relatedness 0.183 0.0502 3.05e-4 0.0843 0.282 0.291 0.272 404 #&gt; 5 Intrinsic 0.165 0.0622 8.37e-3 0.0426 0.287 0.291 0.272 404 #&gt; 6 Extrinsic -0.174 0.0431 6.27e-5 -0.259 -0.0896 0.291 0.272 404 #&gt; 7 Hours 0.0474 0.0416 2.55e-1 -0.0344 0.129 0.291 0.272 404 #&gt; 8 Autonomy:Hours 0.0361 0.0685 5.98e-1 -0.0985 0.171 0.291 0.272 404 #&gt; 9 Competence:Hou… -0.0667 0.0667 3.18e-1 -0.198 0.0644 0.291 0.272 404 #&gt; 10 Relatedness:Ho… -0.0154 0.0456 7.36e-1 -0.105 0.0743 0.291 0.272 404 #&gt; 11 Intrinsic:Hours 0.0396 0.0681 5.62e-1 -0.0944 0.174 0.291 0.272 404 #&gt; 12 Extrinsic:Hours 0.00121 0.0375 9.74e-1 -0.0724 0.0749 0.291 0.272 404 #&gt; #&gt; [[2]] #&gt; # A tibble: 12 x 9 #&gt; term estimate SE p.value conf.low conf.high r2 r2a nobs #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 (Intercept) 0.125 0.0256 1.23e- 6 0.0745 0.175 0.145 0.138 1430 #&gt; 2 Autonomy 0.173 0.0384 7.03e- 6 0.0978 0.248 0.145 0.138 1430 #&gt; 3 Competence 0.0511 0.0334 1.26e- 1 -0.0144 0.117 0.145 0.138 1430 #&gt; 4 Relatedness 0.127 0.0312 5.23e- 5 0.0654 0.188 0.145 0.138 1430 #&gt; 5 Intrinsic 0.0260 0.0362 4.74e- 1 -0.0451 0.0970 0.145 0.138 1430 #&gt; 6 Extrinsic -0.316 0.0264 1.56e-31 -0.368 -0.264 0.145 0.138 1430 #&gt; 7 Hours 0.0283 0.0199 1.55e- 1 -0.0107 0.0672 0.145 0.138 1430 #&gt; 8 Autonomy:Hours 0.0287 0.0300 3.38e- 1 -0.0301 0.0876 0.145 0.138 1430 #&gt; 9 Competence:Hou… -0.0217 0.0275 4.31e- 1 -0.0757 0.0323 0.145 0.138 1430 #&gt; 10 Relatedness:Ho… -0.0142 0.0220 5.18e- 1 -0.0574 0.0289 0.145 0.138 1430 #&gt; 11 Intrinsic:Hours -0.0107 0.0275 6.97e- 1 -0.0647 0.0433 0.145 0.138 1430 #&gt; 12 Extrinsic:Hours -0.0129 0.0182 4.76e- 1 -0.0486 0.0227 0.145 0.138 1430 We also compared the omnibus estimates to independent estimates p1 %+% drop_na(tmp) + aes(col = Model) + facet_wrap(&quot;Game&quot;) 5.4 Nonlinear models We also investigated potential nonlinear relations between game time and wellbeing. We did so by fitting a model with and without a smooth term, and using AIC to compare the models. dat %&gt;% select(Game, Spane_balance, Hours10, Active_play10) %&gt;% pivot_longer(contains(&quot;10&quot;)) %&gt;% ggplot(aes(value, Spane_balance)) + geom_point() + geom_smooth(method = &quot;lm&quot;, aes(col = &quot;linear&quot;)) + geom_smooth(method = &quot;gam&quot;, aes(col = &quot;GAM&quot;)) + facet_grid(name~Game, scales = &quot;free&quot;) library(mgcv) dat %&gt;% select(Game, Spane_balance, Hours10, Active_play10) %&gt;% pivot_longer(contains(&quot;10&quot;), names_to = &quot;Variable&quot;) %&gt;% group_by(Game, Variable) %&gt;% nest() %&gt;% mutate(linear = map(data, ~gam(Spane_balance ~ value, data = .x))) %&gt;% mutate(smooth = map(data, ~gam(Spane_balance ~ s(value), data = .x))) %&gt;% pivot_longer(linear:smooth, names_to = &quot;Model&quot;) %&gt;% mutate(AIC = map_dbl(value, AIC)) %&gt;% select(Game, Variable, Model, AIC) %&gt;% pivot_wider(names_from = Model, values_from = AIC) %&gt;% mutate(Difference = linear-smooth) %&gt;% kable(digits = 1) Game Variable linear smooth Difference PvZ Hours10 1337.7 1337.7 0.0 PvZ Active_play10 1468.1 1464.4 3.7 AC:NH Hours10 7218.9 7218.2 0.8 AC:NH Active_play10 15512.7 15506.6 6.1 5.5 System information sessionInfo() #&gt; R version 4.0.3 (2020-10-10) #&gt; Platform: x86_64-pc-linux-gnu (64-bit) #&gt; Running under: Ubuntu 20.04.1 LTS #&gt; #&gt; Matrix products: default #&gt; BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 #&gt; LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 #&gt; #&gt; locale: #&gt; [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 #&gt; [4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8 #&gt; [7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C #&gt; [10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] mgcv_1.8-33 nlme_3.1-150 forcats_0.5.0 stringr_1.4.0 #&gt; [5] dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 #&gt; [9] tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 ggstance_0.3.4 #&gt; [13] broom_0.7.2 scales_1.1.1 patchwork_1.1.0 knitr_1.30 #&gt; [17] here_1.0.1 pacman_0.5.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] Rcpp_1.0.5 lubridate_1.7.9.2 lattice_0.20-41 assertthat_0.2.1 #&gt; [5] rprojroot_2.0.2 digest_0.6.27 utf8_1.1.4 R6_2.5.0 #&gt; [9] cellranger_1.1.0 backports_1.2.1 reprex_0.3.0 evaluate_0.14 #&gt; [13] httr_1.4.2 highr_0.8 pillar_1.4.7 rlang_0.4.9 #&gt; [17] readxl_1.3.1 rstudioapi_0.13 Matrix_1.2-18 rmarkdown_2.6 #&gt; [21] labeling_0.4.2 splines_4.0.3 munsell_0.5.0 compiler_4.0.3 #&gt; [25] modelr_0.1.8 xfun_0.19 pkgconfig_2.0.3 htmltools_0.5.0 #&gt; [29] tidyselect_1.1.0 bookdown_0.21 fansi_0.4.1 crayon_1.3.4 #&gt; [33] dbplyr_2.0.0 withr_2.3.0 grid_4.0.3 jsonlite_1.7.2 #&gt; [37] gtable_0.3.0 lifecycle_0.2.0 DBI_1.1.0 magrittr_2.0.1 #&gt; [41] cli_2.2.0 stringi_1.5.3 farver_2.0.3 fs_1.5.0 #&gt; [45] xml2_1.3.2 ellipsis_0.3.1 generics_0.1.0 vctrs_0.3.5 #&gt; [49] tools_4.0.3 glue_1.4.2 hms_0.5.3 parallel_4.0.3 #&gt; [53] yaml_2.2.1 colorspace_2.0-0 rvest_0.3.6 haven_2.3.1 "]]
